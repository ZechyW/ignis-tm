<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.9.2" />
<title>ignis.corpus API documentation</title>
<meta name="description" content="" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">import bz2
import collections
import json
import pathlib
import pickle
import re
import uuid

from bs4 import BeautifulSoup


class Corpus:
    &#34;&#34;&#34;
    A container for holding all the Documents relevant to a particular dataset.

    The same Corpus will be used even as sub-slices of the data go through iterative
    modelling -- Smaller sets of Documents will just be selected by ID.

    Corpora Documents are tracked by insertion order, but CorpusSlices are shuffled
    (viz., they are sorted by the randomly-generated Document IDs).

    Attributes
    ----------
    documents: dict
        A mapping of Document IDs to the corresponding Documents.
    &#34;&#34;&#34;

    def __init__(self):
        self.documents = collections.OrderedDict()

    def add_doc(self, tokens, metadata=None, display_str=None, plain_text=None):
        &#34;&#34;&#34;
        Creates a new Document with the given parameters and starts tracking it.

        Parameters
        ----------
        tokens: iterable of str
            The individual content tokens in the given document; will be fed directly
            into the various topic modelling algorithms. Assumed to have already
            undergone any necessary munging.
        metadata: dict, optional
            A general-purpose dictionary containing any metadata the user wants to
            track.
        display_str: str, optional
            The content of the document, as a single string containing any necessary
            markup or other formatting for human-readable display. By default,
            `display_str` is assumed to contain a HTML representation of the document
            (e.g., when the document is rendered in `ignis.aurum.nb_explore_topics()`),
            but a custom display function can be passed where necessary.
            If None, will use the Document tokens joined with single spaces.
        plain_text: str, optional
            The full text of the given document as a single normalised string. If
            `plain_text` is None, `display_str` is assumed to contain a HTML
            representation of the document, and a corresponding plain-text
            representation is automatically generated via BeautifulSoup when the
            attribute is first accessed.

        Returns
        -------
        str
            The ID for the added Document
        &#34;&#34;&#34;
        if len(tokens) == 0:
            raise RuntimeError(&#34;Cannot add a Document with no tokens to a Corpus.&#34;)

        if metadata is None:
            metadata = collections.OrderedDict()
        if display_str is None:
            display_str = &#34; &#34;.join(tokens)
        doc = Document(tokens, metadata, display_str, plain_text)
        if doc.id in self.documents:
            raise RuntimeError(
                f&#34;This Document&#39;s hash is already present in the Corpus; it may be a &#34;
                f&#34;duplicate. Ignoring.\n&#34;
                f&#34;(If this is a genuine hash collision, create a new Document with &#34;
                f&#34;different metadata values and try adding it again.)\n&#34;
                f&#34;{doc.id}\n&#34;
                f&#34;{doc.tokens}{doc.metadata}{doc.display_str}&#34;
            )
        self.documents[doc.id] = doc
        return doc.id

    def save(self, filename):
        &#34;&#34;&#34;
        Saves the Corpus object to the given file.
        Essentially uses a bz2-compressed Pickle format.

        Parameters
        ----------
        filename: str or pathlib.Path
            File to save the Corpus to
        &#34;&#34;&#34;
        filename = pathlib.Path(filename)
        with bz2.open(filename, &#34;wb&#34;) as fp:
            pickle.dump(self, fp)

    def slice_full(self):
        &#34;&#34;&#34;
        Get a CorpusSlice containing all the documents in this Corpus.

        Returns
        -------
        CorpusSlice
        &#34;&#34;&#34;
        return CorpusSlice(root=self, slice_ids=list(self.documents))


class CorpusSlice:
    &#34;&#34;&#34;
    Contains some subset of the Documents in a Corpus, and keeps a reference to the
    root Corpus for bookkeeping and iteration.

    Parameters
    ----------
    root: Corpus
        The root Corpus instance for this slice.
    slice_ids: iterable of str
        The IDs for the documents in this slice.

    Attributes
    ----------
    documents: collections.OrderedDict
        Mapping of IDs to Documents.  Ordered by Document ID as a form of shuffling
        (useful for things like preventing time bias in the document order).
    &#34;&#34;&#34;

    def __init__(self, root, slice_ids):
        self.root = root
        self.documents = collections.OrderedDict()
        slice_ids.sort()
        for slice_id in slice_ids:
            self.documents[slice_id] = root.documents[slice_id]

    def __len__(self):
        return len(self.documents)

    def document_ids(self):
        return list(self.documents.keys())

    def get_document(self, doc_id):
        &#34;&#34;&#34;
        Return the Document from this CorpusSlice with the given ID.

        Parameters
        ----------
        doc_id: str or uuid.UUID

        Returns
        -------
        Document
        &#34;&#34;&#34;
        if isinstance(doc_id, str):
            doc_id = uuid.UUID(doc_id)
        return self.documents[doc_id]

    def save(self, filename):
        &#34;&#34;&#34;
        Saves the CorpusSlice object to the given file.
        Essentially uses a bz2-compressed Pickle format.

        Parameters
        ----------
        filename: str or pathlib.Path
            File to save the Corpus to
        &#34;&#34;&#34;
        filename = pathlib.Path(filename)
        with bz2.open(filename, &#34;wb&#34;) as fp:
            pickle.dump(self, fp)

    def slice_by_ids(self, doc_ids):
        &#34;&#34;&#34;
        Create a new CorpusSlice with the given Document IDs.
        The IDs do not have to be part of this CorpusSlice, as long as they are a
        part of the root Corpus.

        Parameters
        ----------
        doc_ids: iterable of str
            List of Document IDs

        Returns
        -------
        CorpusSlice
        &#34;&#34;&#34;
        # Sanity check
        if type(doc_ids) is str:
            raise RuntimeWarning(
                &#34;Received a single string instead of an iterable of Document ID &#34;
                &#34;strings -- You probably did not intend to do this.&#34;
            )

        return CorpusSlice(self.root, doc_ids)

    def slice_by_tokens(self, tokens, include_root=False, plain_text=False):
        &#34;&#34;&#34;
        Create a new CorpusSlice with Documents that contain at least one of the
        given tokens.

        If `plain_text` is True, will match `tokens` against the plain-text
        representation of the Document rather than its raw tokens (which might have
        undergone various transformations).

        `tokens` is canonically an iterable of single tokens, but if `plain_text` is
        set, a search will be done using the literal text of each element, allowing
        for exact phrase matching as well.

        If `include_root` is True, will also search the root Corpus for Documents
        instead of limiting the search to the current CorpusSlice.

        Parameters
        ----------
        tokens: iterable of str
            A list of the tokens to search Documents for
        include_root: bool, optional
            Whether or not to search the root Corpus as well
        plain_text: bool, optional
            Whether or not to search the plain-text representation of the Document
            rather than its tokenised form

        Returns
        -------
        CorpusSlice
        &#34;&#34;&#34;
        # Sanity check
        if type(tokens) is str:
            raise RuntimeWarning(
                &#34;Received a single string instead of an iterable of token &#34;
                &#34;strings -- You probably did not intend to do this.&#34;
            )

        if include_root:
            search_docs = self.root.documents
        else:
            search_docs = self.documents

        # By-token search matches tokens directly
        search_tokens = set(tokens)

        # Plain-text search performs a regex text search
        search_patterns = [
            re.compile(fr&#34;(\s|^){re.escape(token)}(\s|$)&#34;) for token in tokens
        ]

        found_doc_ids = []
        for doc_id, doc in search_docs.items():
            if plain_text:
                doc_text = doc.plain_text

                found_pattern = False
                for pattern in search_patterns:
                    if pattern.search(doc_text):
                        found_pattern = True
                        break

                if found_pattern:
                    found_doc_ids.append(doc_id)

            else:
                doc_tokens = set(doc.tokens)
                if len(search_tokens &amp; doc_tokens) &gt; 0:
                    found_doc_ids.append(doc_id)

        return self.slice_by_ids(found_doc_ids)

    def slice_without_tokens(self, tokens, include_root=False, plain_text=False):
        &#34;&#34;&#34;
        Returns a new CorpusSlice with the Documents that contain `tokens` removed.

        If `plain_text` is True, will match `tokens` against the plain-text
        representation of the Document rather than its raw tokens (which might have
        undergone various transformations).

        `tokens` is canonically an iterable of single tokens, but if `plain_text` is
        set, a search will be done using the literal text of each element, allowing
        for exact phrase matching as well.

        If `include_root` is True, will also search the root Corpus for Documents
        instead of limiting the search to the current CorpusSlice.

        Parameters
        ----------
        tokens: iterable of str
            The tokens (or phrases) to remove
        include_root: bool, optional
            Whether or not to search the root Corpus as well
        plain_text: bool, optional
            Whether or not to search the plain-text representation of the Document
            rather than its tokenised form

        Returns
        -------
        CorpusSlice
        &#34;&#34;&#34;
        # Sanity check
        if type(tokens) is str:
            raise RuntimeWarning(
                &#34;Received a single string instead of an iterable of token &#34;
                &#34;strings -- You probably did not intend to do this.&#34;
            )

        if include_root:
            search_docs = self.root.documents
        else:
            search_docs = self.documents

        # By-token search matches tokens directly
        search_tokens = set(tokens)

        # Plain-text search performs a regex text search
        search_patterns = [
            re.compile(fr&#34;(\s|^){re.escape(token)}(\s|$)&#34;) for token in tokens
        ]

        filtered_doc_ids = []
        for doc_id, doc in search_docs.items():
            if plain_text:
                doc_text = doc.plain_text

                found_pattern = False
                for pattern in search_patterns:
                    if pattern.search(doc_text):
                        found_pattern = True
                        break

                if not found_pattern:
                    filtered_doc_ids.append(doc_id)

            else:
                doc_tokens = set(doc.tokens)
                if len(search_tokens &amp; doc_tokens) == 0:
                    filtered_doc_ids.append(doc_id)

        return self.slice_by_ids(filtered_doc_ids)

    def slice_filter(self, filter_fn, include_root=False):
        &#34;&#34;&#34;
        Returns a new CorpusSlice with the Documents that `filter_fn` returns True for.

        `filter_fn` receives one argument, a single Document in this CorpusSlice.

        Parameters
        ----------
        filter_fn: fn
            The filter function
        include_root: bool, optional
            Whether or not to search the root Corpus as well

        Returns
        -------
        CorpusSlice
        &#34;&#34;&#34;
        if include_root:
            search_docs = self.root.documents
        else:
            search_docs = self.documents

        filtered_doc_ids = []
        for doc_id, doc in search_docs.items():
            if filter_fn(doc):
                filtered_doc_ids.append(doc_id)

        return self.slice_by_ids(filtered_doc_ids)

    def concat(self, *other_slices):
        &#34;&#34;&#34;
        Returns a new CorpusSlice that has the Documents from this instance and all
        the other specified CorpusSlices.

        Will retain the root Corpus from this instance.

        Parameters
        ----------
        other_slices: iterable of CorpusSlice

        Returns
        -------
        CorpusSlice
        &#34;&#34;&#34;
        new_slice_ids = set(self.documents.keys())

        for other_slice in other_slices:
            if not isinstance(other_slice, CorpusSlice):
                raise RuntimeError(
                    &#34;CorpusSlices can only be concatenated with other CorpusSlices.&#34;
                )

            if other_slice.root != self.root:
                raise RuntimeError(
                    &#34;CorpusSlices can only be concatenated if they have the same root &#34;
                    &#34;Corpus.&#34;
                )

            slice_ids = set(other_slice.documents)
            new_slice_ids = new_slice_ids | slice_ids

        new_slice_ids = list(new_slice_ids)

        return CorpusSlice(self.root, new_slice_ids)

    def __add__(self, other):
        return self.concat(other)

    def __eq__(self, other):
        return (
            isinstance(other, CorpusSlice)
            and self.root == other.root
            and self.documents == other.documents
        )

    def nb_explore(self, doc_sort_key=None, reverse=False, display_fn=None):
        &#34;&#34;&#34;
        Convenience function that creates an interactive Jupyter notebook widget for
        exploring the Documents contained in this CorpusSlice.

        Documents do not have any sort order imposed on them by default, but a custom
        sorting function can be passed via `doc_sort_key` as well.

        Parameters
        ----------
        doc_sort_key: fn, optional
            If specified, will sort documents using this key when displaying them.
        reverse: bool, optional
            Sets the sort direction for `doc_sort_key`, if specified.
        display_fn: fn, optional
            Custom display function that receives an individual Document as input and
            should display the Document in human-readable form as a side effect.
            If unset, will assume that the human-readable representation of the
            Document is in HTML format and display it accordingly.

        Returns
        -------
        ipywidgets.interact function
        &#34;&#34;&#34;
        import ipywidgets
        from IPython.core.display import display, HTML

        docs = list(self.documents.values())

        if doc_sort_key is not None:
            docs = sorted(docs, key=doc_sort_key, reverse=reverse)

        def show_doc(index=0):
            print(f&#34;[Total documents: {len(docs)}]\n&#34;)
            doc = docs[index]

            if display_fn is None:
                # Default HTML display
                print(f&#34;ID: {doc.id}&#34;)
                if &#34;filename&#34; in doc.metadata:
                    print(f&#34;Filename: {doc.metadata[&#39;filename&#39;]}&#34;)

                # Jupyter notebooks will interpret anything between $ signs
                # as LaTeX formulae when rendering HTML output, so we need to
                # replace them with escaped $ signs (only in Jupyter
                # environments)
                display_str = doc.display_str.replace(&#34;$&#34;, r&#34;\$&#34;)

                # noinspection PyTypeChecker
                display(HTML(display_str))
            else:
                # User-provided display function
                display_fn(doc)

        return ipywidgets.interact(
            show_doc,
            index=ipywidgets.IntSlider(
                description=&#34;Document&#34;, min=0, max=len(docs) - 1
            ),
        )


class Document(object):
    &#34;&#34;&#34;
    Documents hold the textual content of each file in the Corpus, as well as any
    relevant metadata.

    Parameters
    ----------
    tokens: iterable of str
        The individual content tokens in the given document; will be fed directly
        into the various topic modelling algorithms. Assumed to have already
        undergone any necessary munging.
    metadata: dict
        A general-purpose dictionary containing any metadata the user wants to
        track.
    display_str: str
        The content of the document, as a single string containing any necessary
        markup or other formatting for human-readable display. By default,
        `display_str` is assumed to contain a HTML representation of the document (
        e.g., when the document is rendered in `ignis.aurum.nb_explore_topics()`),
        but a custom display function can be passed where necessary.
    plain_text: str, optional
        The full text of the given document as a single normalised string. If
        `plain_text` is None, `display_str` is assumed to contain a HTML representation
        of the document, and a corresponding plain-text representation is
        automatically generated via BeautifulSoup when the attribute is first accessed.
    &#34;&#34;&#34;

    # Let&#39;s make Document IDs deterministic on their data, so that multiple runs of a
    # Corpus creation script don&#39;t generate different IDs.
    # We will create a UUID5 for each Document against this fixed namespace:
    ignis_uuid_namespace = uuid.UUID(&#34;58ca78f2-0347-4b96-b2e7-63796bf87889&#34;)

    def __init__(self, tokens, metadata, display_str, plain_text=None):
        self.tokens = tokens
        self.metadata = metadata
        self.display_str = display_str
        self.plain_text = plain_text

        data = f&#34;{tokens}{metadata}{display_str}&#34;
        self.id = uuid.uuid5(Document.ignis_uuid_namespace, data)

    def __str__(self):
        metadata = json.dumps(self.metadata, indent=2)

        truncated = []
        for line in metadata.splitlines():
            if len(line) &gt; 120:
                truncated.append(f&#34;{line[:120]}...&#34;)
            else:
                truncated.append(line)
        metadata = &#34;\n&#34;.join(truncated)

        return f&#34;ID: {self.id}\n\nMetadata: {metadata}\n\n&#34; f&#34;{self.display_str}&#34;

    def __getattribute__(self, item):
        if item == &#34;plain_text&#34; and object.__getattribute__(self, &#34;plain_text&#34;) is None:
            # There is no `plain_text` set for this document; assume that
            # `display_str` contains a HTML representation of the document.
            soup = BeautifulSoup(self.display_str, &#34;lxml&#34;)

            # The text returned by BeautifulSoup might contain whitespace --
            # Concatenate, split, and concatenate again to normalise the spacing
            self.plain_text = &#34; &#34;.join(soup.get_text().split())
            return self.plain_text
        return object.__getattribute__(self, item)


def load_corpus(filename):
    &#34;&#34;&#34;
    Loads a Corpus object from the given file.

    Conceptually, Corpus objects contain the full amount of data for a given dataset.

    Some subset of the Corpus (up to the full Corpus itself) must be sliced into a
    CorpusSlice to perform topic modelling over the data, and these CorpusSlices can
    be iteratively expanded or contracted freely within the full set of Corpus data.

    Parameters
    ----------
    filename: str or pathlib.Path
        The file to load the Corpus object from.

    Returns
    -------
    ignis.corpus.Corpus
    &#34;&#34;&#34;
    with bz2.open(filename, &#34;rb&#34;) as fp:
        loaded = pickle.load(fp)

    if not isinstance(loaded, Corpus):
        raise ValueError(f&#34;File does not contain a Corpus object: &#39;{filename}&#39;&#34;)

    return loaded


def load_slice(filename):
    &#34;&#34;&#34;
    Loads a CorpusSlice object from the given file.

    CorpusSlices contain a specific subset of some root Corpus, and can be passed
    directly as input into topic models.

    Parameters
    ----------
    filename: str or pathlib.Path
        The file to load the CorpusSlice object from.

    Returns
    -------
    ignis.corpus.CorpusSlice
    &#34;&#34;&#34;
    with bz2.open(filename, &#34;rb&#34;) as fp:
        loaded = pickle.load(fp)

    if not isinstance(loaded, CorpusSlice):
        raise ValueError(f&#34;File does not contain a CorpusSlice object: &#39;{filename}&#39;&#34;)

    return loaded</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="ignis.corpus.load_corpus"><code class="name flex">
<span>def <span class="ident">load_corpus</span></span>(<span>filename)</span>
</code></dt>
<dd>
<div class="desc"><p>Loads a Corpus object from the given file.</p>
<p>Conceptually, Corpus objects contain the full amount of data for a given dataset.</p>
<p>Some subset of the Corpus (up to the full Corpus itself) must be sliced into a
CorpusSlice to perform topic modelling over the data, and these CorpusSlices can
be iteratively expanded or contracted freely within the full set of Corpus data.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>filename</code></strong> :&ensp;<code>str</code> or <code>pathlib.Path</code></dt>
<dd>The file to load the Corpus object from.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code><a title="ignis.corpus.Corpus" href="#ignis.corpus.Corpus">Corpus</a></code></dt>
<dd>&nbsp;</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def load_corpus(filename):
    &#34;&#34;&#34;
    Loads a Corpus object from the given file.

    Conceptually, Corpus objects contain the full amount of data for a given dataset.

    Some subset of the Corpus (up to the full Corpus itself) must be sliced into a
    CorpusSlice to perform topic modelling over the data, and these CorpusSlices can
    be iteratively expanded or contracted freely within the full set of Corpus data.

    Parameters
    ----------
    filename: str or pathlib.Path
        The file to load the Corpus object from.

    Returns
    -------
    ignis.corpus.Corpus
    &#34;&#34;&#34;
    with bz2.open(filename, &#34;rb&#34;) as fp:
        loaded = pickle.load(fp)

    if not isinstance(loaded, Corpus):
        raise ValueError(f&#34;File does not contain a Corpus object: &#39;{filename}&#39;&#34;)

    return loaded</code></pre>
</details>
</dd>
<dt id="ignis.corpus.load_slice"><code class="name flex">
<span>def <span class="ident">load_slice</span></span>(<span>filename)</span>
</code></dt>
<dd>
<div class="desc"><p>Loads a CorpusSlice object from the given file.</p>
<p>CorpusSlices contain a specific subset of some root Corpus, and can be passed
directly as input into topic models.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>filename</code></strong> :&ensp;<code>str</code> or <code>pathlib.Path</code></dt>
<dd>The file to load the CorpusSlice object from.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code><a title="ignis.corpus.CorpusSlice" href="#ignis.corpus.CorpusSlice">CorpusSlice</a></code></dt>
<dd>&nbsp;</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def load_slice(filename):
    &#34;&#34;&#34;
    Loads a CorpusSlice object from the given file.

    CorpusSlices contain a specific subset of some root Corpus, and can be passed
    directly as input into topic models.

    Parameters
    ----------
    filename: str or pathlib.Path
        The file to load the CorpusSlice object from.

    Returns
    -------
    ignis.corpus.CorpusSlice
    &#34;&#34;&#34;
    with bz2.open(filename, &#34;rb&#34;) as fp:
        loaded = pickle.load(fp)

    if not isinstance(loaded, CorpusSlice):
        raise ValueError(f&#34;File does not contain a CorpusSlice object: &#39;{filename}&#39;&#34;)

    return loaded</code></pre>
</details>
</dd>
</dl>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="ignis.corpus.Corpus"><code class="flex name class">
<span>class <span class="ident">Corpus</span></span>
</code></dt>
<dd>
<div class="desc"><p>A container for holding all the Documents relevant to a particular dataset.</p>
<p>The same Corpus will be used even as sub-slices of the data go through iterative
modelling &ndash; Smaller sets of Documents will just be selected by ID.</p>
<p>Corpora Documents are tracked by insertion order, but CorpusSlices are shuffled
(viz., they are sorted by the randomly-generated Document IDs).</p>
<h2 id="attributes">Attributes</h2>
<dl>
<dt><strong><code>documents</code></strong> :&ensp;<code>dict</code></dt>
<dd>A mapping of Document IDs to the corresponding Documents.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class Corpus:
    &#34;&#34;&#34;
    A container for holding all the Documents relevant to a particular dataset.

    The same Corpus will be used even as sub-slices of the data go through iterative
    modelling -- Smaller sets of Documents will just be selected by ID.

    Corpora Documents are tracked by insertion order, but CorpusSlices are shuffled
    (viz., they are sorted by the randomly-generated Document IDs).

    Attributes
    ----------
    documents: dict
        A mapping of Document IDs to the corresponding Documents.
    &#34;&#34;&#34;

    def __init__(self):
        self.documents = collections.OrderedDict()

    def add_doc(self, tokens, metadata=None, display_str=None, plain_text=None):
        &#34;&#34;&#34;
        Creates a new Document with the given parameters and starts tracking it.

        Parameters
        ----------
        tokens: iterable of str
            The individual content tokens in the given document; will be fed directly
            into the various topic modelling algorithms. Assumed to have already
            undergone any necessary munging.
        metadata: dict, optional
            A general-purpose dictionary containing any metadata the user wants to
            track.
        display_str: str, optional
            The content of the document, as a single string containing any necessary
            markup or other formatting for human-readable display. By default,
            `display_str` is assumed to contain a HTML representation of the document
            (e.g., when the document is rendered in `ignis.aurum.nb_explore_topics()`),
            but a custom display function can be passed where necessary.
            If None, will use the Document tokens joined with single spaces.
        plain_text: str, optional
            The full text of the given document as a single normalised string. If
            `plain_text` is None, `display_str` is assumed to contain a HTML
            representation of the document, and a corresponding plain-text
            representation is automatically generated via BeautifulSoup when the
            attribute is first accessed.

        Returns
        -------
        str
            The ID for the added Document
        &#34;&#34;&#34;
        if len(tokens) == 0:
            raise RuntimeError(&#34;Cannot add a Document with no tokens to a Corpus.&#34;)

        if metadata is None:
            metadata = collections.OrderedDict()
        if display_str is None:
            display_str = &#34; &#34;.join(tokens)
        doc = Document(tokens, metadata, display_str, plain_text)
        if doc.id in self.documents:
            raise RuntimeError(
                f&#34;This Document&#39;s hash is already present in the Corpus; it may be a &#34;
                f&#34;duplicate. Ignoring.\n&#34;
                f&#34;(If this is a genuine hash collision, create a new Document with &#34;
                f&#34;different metadata values and try adding it again.)\n&#34;
                f&#34;{doc.id}\n&#34;
                f&#34;{doc.tokens}{doc.metadata}{doc.display_str}&#34;
            )
        self.documents[doc.id] = doc
        return doc.id

    def save(self, filename):
        &#34;&#34;&#34;
        Saves the Corpus object to the given file.
        Essentially uses a bz2-compressed Pickle format.

        Parameters
        ----------
        filename: str or pathlib.Path
            File to save the Corpus to
        &#34;&#34;&#34;
        filename = pathlib.Path(filename)
        with bz2.open(filename, &#34;wb&#34;) as fp:
            pickle.dump(self, fp)

    def slice_full(self):
        &#34;&#34;&#34;
        Get a CorpusSlice containing all the documents in this Corpus.

        Returns
        -------
        CorpusSlice
        &#34;&#34;&#34;
        return CorpusSlice(root=self, slice_ids=list(self.documents))</code></pre>
</details>
<h3>Methods</h3>
<dl>
<dt id="ignis.corpus.Corpus.add_doc"><code class="name flex">
<span>def <span class="ident">add_doc</span></span>(<span>self, tokens, metadata=None, display_str=None, plain_text=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Creates a new Document with the given parameters and starts tracking it.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>tokens</code></strong> :&ensp;<code>iterable</code> of <code>str</code></dt>
<dd>The individual content tokens in the given document; will be fed directly
into the various topic modelling algorithms. Assumed to have already
undergone any necessary munging.</dd>
<dt><strong><code>metadata</code></strong> :&ensp;<code>dict</code>, optional</dt>
<dd>A general-purpose dictionary containing any metadata the user wants to
track.</dd>
<dt><strong><code>display_str</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>The content of the document, as a single string containing any necessary
markup or other formatting for human-readable display. By default,
<code>display_str</code> is assumed to contain a HTML representation of the document
(e.g., when the document is rendered in <code>ignis.aurum.nb_explore_topics()</code>),
but a custom display function can be passed where necessary.
If None, will use the Document tokens joined with single spaces.</dd>
<dt><strong><code>plain_text</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>The full text of the given document as a single normalised string. If
<code>plain_text</code> is None, <code>display_str</code> is assumed to contain a HTML
representation of the document, and a corresponding plain-text
representation is automatically generated via BeautifulSoup when the
attribute is first accessed.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>str</code></dt>
<dd>The ID for the added Document</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def add_doc(self, tokens, metadata=None, display_str=None, plain_text=None):
    &#34;&#34;&#34;
    Creates a new Document with the given parameters and starts tracking it.

    Parameters
    ----------
    tokens: iterable of str
        The individual content tokens in the given document; will be fed directly
        into the various topic modelling algorithms. Assumed to have already
        undergone any necessary munging.
    metadata: dict, optional
        A general-purpose dictionary containing any metadata the user wants to
        track.
    display_str: str, optional
        The content of the document, as a single string containing any necessary
        markup or other formatting for human-readable display. By default,
        `display_str` is assumed to contain a HTML representation of the document
        (e.g., when the document is rendered in `ignis.aurum.nb_explore_topics()`),
        but a custom display function can be passed where necessary.
        If None, will use the Document tokens joined with single spaces.
    plain_text: str, optional
        The full text of the given document as a single normalised string. If
        `plain_text` is None, `display_str` is assumed to contain a HTML
        representation of the document, and a corresponding plain-text
        representation is automatically generated via BeautifulSoup when the
        attribute is first accessed.

    Returns
    -------
    str
        The ID for the added Document
    &#34;&#34;&#34;
    if len(tokens) == 0:
        raise RuntimeError(&#34;Cannot add a Document with no tokens to a Corpus.&#34;)

    if metadata is None:
        metadata = collections.OrderedDict()
    if display_str is None:
        display_str = &#34; &#34;.join(tokens)
    doc = Document(tokens, metadata, display_str, plain_text)
    if doc.id in self.documents:
        raise RuntimeError(
            f&#34;This Document&#39;s hash is already present in the Corpus; it may be a &#34;
            f&#34;duplicate. Ignoring.\n&#34;
            f&#34;(If this is a genuine hash collision, create a new Document with &#34;
            f&#34;different metadata values and try adding it again.)\n&#34;
            f&#34;{doc.id}\n&#34;
            f&#34;{doc.tokens}{doc.metadata}{doc.display_str}&#34;
        )
    self.documents[doc.id] = doc
    return doc.id</code></pre>
</details>
</dd>
<dt id="ignis.corpus.Corpus.save"><code class="name flex">
<span>def <span class="ident">save</span></span>(<span>self, filename)</span>
</code></dt>
<dd>
<div class="desc"><p>Saves the Corpus object to the given file.
Essentially uses a bz2-compressed Pickle format.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>filename</code></strong> :&ensp;<code>str</code> or <code>pathlib.Path</code></dt>
<dd>File to save the Corpus to</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def save(self, filename):
    &#34;&#34;&#34;
    Saves the Corpus object to the given file.
    Essentially uses a bz2-compressed Pickle format.

    Parameters
    ----------
    filename: str or pathlib.Path
        File to save the Corpus to
    &#34;&#34;&#34;
    filename = pathlib.Path(filename)
    with bz2.open(filename, &#34;wb&#34;) as fp:
        pickle.dump(self, fp)</code></pre>
</details>
</dd>
<dt id="ignis.corpus.Corpus.slice_full"><code class="name flex">
<span>def <span class="ident">slice_full</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Get a CorpusSlice containing all the documents in this Corpus.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code><a title="ignis.corpus.CorpusSlice" href="#ignis.corpus.CorpusSlice">CorpusSlice</a></code></dt>
<dd>&nbsp;</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def slice_full(self):
    &#34;&#34;&#34;
    Get a CorpusSlice containing all the documents in this Corpus.

    Returns
    -------
    CorpusSlice
    &#34;&#34;&#34;
    return CorpusSlice(root=self, slice_ids=list(self.documents))</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="ignis.corpus.CorpusSlice"><code class="flex name class">
<span>class <span class="ident">CorpusSlice</span></span>
<span>(</span><span>root, slice_ids)</span>
</code></dt>
<dd>
<div class="desc"><p>Contains some subset of the Documents in a Corpus, and keeps a reference to the
root Corpus for bookkeeping and iteration.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>root</code></strong> :&ensp;<code><a title="ignis.corpus.Corpus" href="#ignis.corpus.Corpus">Corpus</a></code></dt>
<dd>The root Corpus instance for this slice.</dd>
<dt><strong><code>slice_ids</code></strong> :&ensp;<code>iterable</code> of <code>str</code></dt>
<dd>The IDs for the documents in this slice.</dd>
</dl>
<h2 id="attributes">Attributes</h2>
<dl>
<dt><strong><code>documents</code></strong> :&ensp;<code>collections.OrderedDict</code></dt>
<dd>Mapping of IDs to Documents.
Ordered by Document ID as a form of shuffling
(useful for things like preventing time bias in the document order).</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class CorpusSlice:
    &#34;&#34;&#34;
    Contains some subset of the Documents in a Corpus, and keeps a reference to the
    root Corpus for bookkeeping and iteration.

    Parameters
    ----------
    root: Corpus
        The root Corpus instance for this slice.
    slice_ids: iterable of str
        The IDs for the documents in this slice.

    Attributes
    ----------
    documents: collections.OrderedDict
        Mapping of IDs to Documents.  Ordered by Document ID as a form of shuffling
        (useful for things like preventing time bias in the document order).
    &#34;&#34;&#34;

    def __init__(self, root, slice_ids):
        self.root = root
        self.documents = collections.OrderedDict()
        slice_ids.sort()
        for slice_id in slice_ids:
            self.documents[slice_id] = root.documents[slice_id]

    def __len__(self):
        return len(self.documents)

    def document_ids(self):
        return list(self.documents.keys())

    def get_document(self, doc_id):
        &#34;&#34;&#34;
        Return the Document from this CorpusSlice with the given ID.

        Parameters
        ----------
        doc_id: str or uuid.UUID

        Returns
        -------
        Document
        &#34;&#34;&#34;
        if isinstance(doc_id, str):
            doc_id = uuid.UUID(doc_id)
        return self.documents[doc_id]

    def save(self, filename):
        &#34;&#34;&#34;
        Saves the CorpusSlice object to the given file.
        Essentially uses a bz2-compressed Pickle format.

        Parameters
        ----------
        filename: str or pathlib.Path
            File to save the Corpus to
        &#34;&#34;&#34;
        filename = pathlib.Path(filename)
        with bz2.open(filename, &#34;wb&#34;) as fp:
            pickle.dump(self, fp)

    def slice_by_ids(self, doc_ids):
        &#34;&#34;&#34;
        Create a new CorpusSlice with the given Document IDs.
        The IDs do not have to be part of this CorpusSlice, as long as they are a
        part of the root Corpus.

        Parameters
        ----------
        doc_ids: iterable of str
            List of Document IDs

        Returns
        -------
        CorpusSlice
        &#34;&#34;&#34;
        # Sanity check
        if type(doc_ids) is str:
            raise RuntimeWarning(
                &#34;Received a single string instead of an iterable of Document ID &#34;
                &#34;strings -- You probably did not intend to do this.&#34;
            )

        return CorpusSlice(self.root, doc_ids)

    def slice_by_tokens(self, tokens, include_root=False, plain_text=False):
        &#34;&#34;&#34;
        Create a new CorpusSlice with Documents that contain at least one of the
        given tokens.

        If `plain_text` is True, will match `tokens` against the plain-text
        representation of the Document rather than its raw tokens (which might have
        undergone various transformations).

        `tokens` is canonically an iterable of single tokens, but if `plain_text` is
        set, a search will be done using the literal text of each element, allowing
        for exact phrase matching as well.

        If `include_root` is True, will also search the root Corpus for Documents
        instead of limiting the search to the current CorpusSlice.

        Parameters
        ----------
        tokens: iterable of str
            A list of the tokens to search Documents for
        include_root: bool, optional
            Whether or not to search the root Corpus as well
        plain_text: bool, optional
            Whether or not to search the plain-text representation of the Document
            rather than its tokenised form

        Returns
        -------
        CorpusSlice
        &#34;&#34;&#34;
        # Sanity check
        if type(tokens) is str:
            raise RuntimeWarning(
                &#34;Received a single string instead of an iterable of token &#34;
                &#34;strings -- You probably did not intend to do this.&#34;
            )

        if include_root:
            search_docs = self.root.documents
        else:
            search_docs = self.documents

        # By-token search matches tokens directly
        search_tokens = set(tokens)

        # Plain-text search performs a regex text search
        search_patterns = [
            re.compile(fr&#34;(\s|^){re.escape(token)}(\s|$)&#34;) for token in tokens
        ]

        found_doc_ids = []
        for doc_id, doc in search_docs.items():
            if plain_text:
                doc_text = doc.plain_text

                found_pattern = False
                for pattern in search_patterns:
                    if pattern.search(doc_text):
                        found_pattern = True
                        break

                if found_pattern:
                    found_doc_ids.append(doc_id)

            else:
                doc_tokens = set(doc.tokens)
                if len(search_tokens &amp; doc_tokens) &gt; 0:
                    found_doc_ids.append(doc_id)

        return self.slice_by_ids(found_doc_ids)

    def slice_without_tokens(self, tokens, include_root=False, plain_text=False):
        &#34;&#34;&#34;
        Returns a new CorpusSlice with the Documents that contain `tokens` removed.

        If `plain_text` is True, will match `tokens` against the plain-text
        representation of the Document rather than its raw tokens (which might have
        undergone various transformations).

        `tokens` is canonically an iterable of single tokens, but if `plain_text` is
        set, a search will be done using the literal text of each element, allowing
        for exact phrase matching as well.

        If `include_root` is True, will also search the root Corpus for Documents
        instead of limiting the search to the current CorpusSlice.

        Parameters
        ----------
        tokens: iterable of str
            The tokens (or phrases) to remove
        include_root: bool, optional
            Whether or not to search the root Corpus as well
        plain_text: bool, optional
            Whether or not to search the plain-text representation of the Document
            rather than its tokenised form

        Returns
        -------
        CorpusSlice
        &#34;&#34;&#34;
        # Sanity check
        if type(tokens) is str:
            raise RuntimeWarning(
                &#34;Received a single string instead of an iterable of token &#34;
                &#34;strings -- You probably did not intend to do this.&#34;
            )

        if include_root:
            search_docs = self.root.documents
        else:
            search_docs = self.documents

        # By-token search matches tokens directly
        search_tokens = set(tokens)

        # Plain-text search performs a regex text search
        search_patterns = [
            re.compile(fr&#34;(\s|^){re.escape(token)}(\s|$)&#34;) for token in tokens
        ]

        filtered_doc_ids = []
        for doc_id, doc in search_docs.items():
            if plain_text:
                doc_text = doc.plain_text

                found_pattern = False
                for pattern in search_patterns:
                    if pattern.search(doc_text):
                        found_pattern = True
                        break

                if not found_pattern:
                    filtered_doc_ids.append(doc_id)

            else:
                doc_tokens = set(doc.tokens)
                if len(search_tokens &amp; doc_tokens) == 0:
                    filtered_doc_ids.append(doc_id)

        return self.slice_by_ids(filtered_doc_ids)

    def slice_filter(self, filter_fn, include_root=False):
        &#34;&#34;&#34;
        Returns a new CorpusSlice with the Documents that `filter_fn` returns True for.

        `filter_fn` receives one argument, a single Document in this CorpusSlice.

        Parameters
        ----------
        filter_fn: fn
            The filter function
        include_root: bool, optional
            Whether or not to search the root Corpus as well

        Returns
        -------
        CorpusSlice
        &#34;&#34;&#34;
        if include_root:
            search_docs = self.root.documents
        else:
            search_docs = self.documents

        filtered_doc_ids = []
        for doc_id, doc in search_docs.items():
            if filter_fn(doc):
                filtered_doc_ids.append(doc_id)

        return self.slice_by_ids(filtered_doc_ids)

    def concat(self, *other_slices):
        &#34;&#34;&#34;
        Returns a new CorpusSlice that has the Documents from this instance and all
        the other specified CorpusSlices.

        Will retain the root Corpus from this instance.

        Parameters
        ----------
        other_slices: iterable of CorpusSlice

        Returns
        -------
        CorpusSlice
        &#34;&#34;&#34;
        new_slice_ids = set(self.documents.keys())

        for other_slice in other_slices:
            if not isinstance(other_slice, CorpusSlice):
                raise RuntimeError(
                    &#34;CorpusSlices can only be concatenated with other CorpusSlices.&#34;
                )

            if other_slice.root != self.root:
                raise RuntimeError(
                    &#34;CorpusSlices can only be concatenated if they have the same root &#34;
                    &#34;Corpus.&#34;
                )

            slice_ids = set(other_slice.documents)
            new_slice_ids = new_slice_ids | slice_ids

        new_slice_ids = list(new_slice_ids)

        return CorpusSlice(self.root, new_slice_ids)

    def __add__(self, other):
        return self.concat(other)

    def __eq__(self, other):
        return (
            isinstance(other, CorpusSlice)
            and self.root == other.root
            and self.documents == other.documents
        )

    def nb_explore(self, doc_sort_key=None, reverse=False, display_fn=None):
        &#34;&#34;&#34;
        Convenience function that creates an interactive Jupyter notebook widget for
        exploring the Documents contained in this CorpusSlice.

        Documents do not have any sort order imposed on them by default, but a custom
        sorting function can be passed via `doc_sort_key` as well.

        Parameters
        ----------
        doc_sort_key: fn, optional
            If specified, will sort documents using this key when displaying them.
        reverse: bool, optional
            Sets the sort direction for `doc_sort_key`, if specified.
        display_fn: fn, optional
            Custom display function that receives an individual Document as input and
            should display the Document in human-readable form as a side effect.
            If unset, will assume that the human-readable representation of the
            Document is in HTML format and display it accordingly.

        Returns
        -------
        ipywidgets.interact function
        &#34;&#34;&#34;
        import ipywidgets
        from IPython.core.display import display, HTML

        docs = list(self.documents.values())

        if doc_sort_key is not None:
            docs = sorted(docs, key=doc_sort_key, reverse=reverse)

        def show_doc(index=0):
            print(f&#34;[Total documents: {len(docs)}]\n&#34;)
            doc = docs[index]

            if display_fn is None:
                # Default HTML display
                print(f&#34;ID: {doc.id}&#34;)
                if &#34;filename&#34; in doc.metadata:
                    print(f&#34;Filename: {doc.metadata[&#39;filename&#39;]}&#34;)

                # Jupyter notebooks will interpret anything between $ signs
                # as LaTeX formulae when rendering HTML output, so we need to
                # replace them with escaped $ signs (only in Jupyter
                # environments)
                display_str = doc.display_str.replace(&#34;$&#34;, r&#34;\$&#34;)

                # noinspection PyTypeChecker
                display(HTML(display_str))
            else:
                # User-provided display function
                display_fn(doc)

        return ipywidgets.interact(
            show_doc,
            index=ipywidgets.IntSlider(
                description=&#34;Document&#34;, min=0, max=len(docs) - 1
            ),
        )</code></pre>
</details>
<h3>Methods</h3>
<dl>
<dt id="ignis.corpus.CorpusSlice.concat"><code class="name flex">
<span>def <span class="ident">concat</span></span>(<span>self, *other_slices)</span>
</code></dt>
<dd>
<div class="desc"><p>Returns a new CorpusSlice that has the Documents from this instance and all
the other specified CorpusSlices.</p>
<p>Will retain the root Corpus from this instance.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>other_slices</code></strong> :&ensp;<code>iterable</code> of <code><a title="ignis.corpus.CorpusSlice" href="#ignis.corpus.CorpusSlice">CorpusSlice</a></code></dt>
<dd>&nbsp;</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code><a title="ignis.corpus.CorpusSlice" href="#ignis.corpus.CorpusSlice">CorpusSlice</a></code></dt>
<dd>&nbsp;</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def concat(self, *other_slices):
    &#34;&#34;&#34;
    Returns a new CorpusSlice that has the Documents from this instance and all
    the other specified CorpusSlices.

    Will retain the root Corpus from this instance.

    Parameters
    ----------
    other_slices: iterable of CorpusSlice

    Returns
    -------
    CorpusSlice
    &#34;&#34;&#34;
    new_slice_ids = set(self.documents.keys())

    for other_slice in other_slices:
        if not isinstance(other_slice, CorpusSlice):
            raise RuntimeError(
                &#34;CorpusSlices can only be concatenated with other CorpusSlices.&#34;
            )

        if other_slice.root != self.root:
            raise RuntimeError(
                &#34;CorpusSlices can only be concatenated if they have the same root &#34;
                &#34;Corpus.&#34;
            )

        slice_ids = set(other_slice.documents)
        new_slice_ids = new_slice_ids | slice_ids

    new_slice_ids = list(new_slice_ids)

    return CorpusSlice(self.root, new_slice_ids)</code></pre>
</details>
</dd>
<dt id="ignis.corpus.CorpusSlice.document_ids"><code class="name flex">
<span>def <span class="ident">document_ids</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def document_ids(self):
    return list(self.documents.keys())</code></pre>
</details>
</dd>
<dt id="ignis.corpus.CorpusSlice.get_document"><code class="name flex">
<span>def <span class="ident">get_document</span></span>(<span>self, doc_id)</span>
</code></dt>
<dd>
<div class="desc"><p>Return the Document from this CorpusSlice with the given ID.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>doc_id</code></strong> :&ensp;<code>str</code> or <code>uuid.UUID</code></dt>
<dd>&nbsp;</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code><a title="ignis.corpus.Document" href="#ignis.corpus.Document">Document</a></code></dt>
<dd>&nbsp;</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_document(self, doc_id):
    &#34;&#34;&#34;
    Return the Document from this CorpusSlice with the given ID.

    Parameters
    ----------
    doc_id: str or uuid.UUID

    Returns
    -------
    Document
    &#34;&#34;&#34;
    if isinstance(doc_id, str):
        doc_id = uuid.UUID(doc_id)
    return self.documents[doc_id]</code></pre>
</details>
</dd>
<dt id="ignis.corpus.CorpusSlice.nb_explore"><code class="name flex">
<span>def <span class="ident">nb_explore</span></span>(<span>self, doc_sort_key=None, reverse=False, display_fn=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Convenience function that creates an interactive Jupyter notebook widget for
exploring the Documents contained in this CorpusSlice.</p>
<p>Documents do not have any sort order imposed on them by default, but a custom
sorting function can be passed via <code>doc_sort_key</code> as well.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>doc_sort_key</code></strong> :&ensp;<code>fn</code>, optional</dt>
<dd>If specified, will sort documents using this key when displaying them.</dd>
<dt><strong><code>reverse</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>Sets the sort direction for <code>doc_sort_key</code>, if specified.</dd>
<dt><strong><code>display_fn</code></strong> :&ensp;<code>fn</code>, optional</dt>
<dd>Custom display function that receives an individual Document as input and
should display the Document in human-readable form as a side effect.
If unset, will assume that the human-readable representation of the
Document is in HTML format and display it accordingly.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>ipywidgets.interact function</code></dt>
<dd>&nbsp;</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def nb_explore(self, doc_sort_key=None, reverse=False, display_fn=None):
    &#34;&#34;&#34;
    Convenience function that creates an interactive Jupyter notebook widget for
    exploring the Documents contained in this CorpusSlice.

    Documents do not have any sort order imposed on them by default, but a custom
    sorting function can be passed via `doc_sort_key` as well.

    Parameters
    ----------
    doc_sort_key: fn, optional
        If specified, will sort documents using this key when displaying them.
    reverse: bool, optional
        Sets the sort direction for `doc_sort_key`, if specified.
    display_fn: fn, optional
        Custom display function that receives an individual Document as input and
        should display the Document in human-readable form as a side effect.
        If unset, will assume that the human-readable representation of the
        Document is in HTML format and display it accordingly.

    Returns
    -------
    ipywidgets.interact function
    &#34;&#34;&#34;
    import ipywidgets
    from IPython.core.display import display, HTML

    docs = list(self.documents.values())

    if doc_sort_key is not None:
        docs = sorted(docs, key=doc_sort_key, reverse=reverse)

    def show_doc(index=0):
        print(f&#34;[Total documents: {len(docs)}]\n&#34;)
        doc = docs[index]

        if display_fn is None:
            # Default HTML display
            print(f&#34;ID: {doc.id}&#34;)
            if &#34;filename&#34; in doc.metadata:
                print(f&#34;Filename: {doc.metadata[&#39;filename&#39;]}&#34;)

            # Jupyter notebooks will interpret anything between $ signs
            # as LaTeX formulae when rendering HTML output, so we need to
            # replace them with escaped $ signs (only in Jupyter
            # environments)
            display_str = doc.display_str.replace(&#34;$&#34;, r&#34;\$&#34;)

            # noinspection PyTypeChecker
            display(HTML(display_str))
        else:
            # User-provided display function
            display_fn(doc)

    return ipywidgets.interact(
        show_doc,
        index=ipywidgets.IntSlider(
            description=&#34;Document&#34;, min=0, max=len(docs) - 1
        ),
    )</code></pre>
</details>
</dd>
<dt id="ignis.corpus.CorpusSlice.save"><code class="name flex">
<span>def <span class="ident">save</span></span>(<span>self, filename)</span>
</code></dt>
<dd>
<div class="desc"><p>Saves the CorpusSlice object to the given file.
Essentially uses a bz2-compressed Pickle format.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>filename</code></strong> :&ensp;<code>str</code> or <code>pathlib.Path</code></dt>
<dd>File to save the Corpus to</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def save(self, filename):
    &#34;&#34;&#34;
    Saves the CorpusSlice object to the given file.
    Essentially uses a bz2-compressed Pickle format.

    Parameters
    ----------
    filename: str or pathlib.Path
        File to save the Corpus to
    &#34;&#34;&#34;
    filename = pathlib.Path(filename)
    with bz2.open(filename, &#34;wb&#34;) as fp:
        pickle.dump(self, fp)</code></pre>
</details>
</dd>
<dt id="ignis.corpus.CorpusSlice.slice_by_ids"><code class="name flex">
<span>def <span class="ident">slice_by_ids</span></span>(<span>self, doc_ids)</span>
</code></dt>
<dd>
<div class="desc"><p>Create a new CorpusSlice with the given Document IDs.
The IDs do not have to be part of this CorpusSlice, as long as they are a
part of the root Corpus.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>doc_ids</code></strong> :&ensp;<code>iterable</code> of <code>str</code></dt>
<dd>List of Document IDs</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code><a title="ignis.corpus.CorpusSlice" href="#ignis.corpus.CorpusSlice">CorpusSlice</a></code></dt>
<dd>&nbsp;</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def slice_by_ids(self, doc_ids):
    &#34;&#34;&#34;
    Create a new CorpusSlice with the given Document IDs.
    The IDs do not have to be part of this CorpusSlice, as long as they are a
    part of the root Corpus.

    Parameters
    ----------
    doc_ids: iterable of str
        List of Document IDs

    Returns
    -------
    CorpusSlice
    &#34;&#34;&#34;
    # Sanity check
    if type(doc_ids) is str:
        raise RuntimeWarning(
            &#34;Received a single string instead of an iterable of Document ID &#34;
            &#34;strings -- You probably did not intend to do this.&#34;
        )

    return CorpusSlice(self.root, doc_ids)</code></pre>
</details>
</dd>
<dt id="ignis.corpus.CorpusSlice.slice_by_tokens"><code class="name flex">
<span>def <span class="ident">slice_by_tokens</span></span>(<span>self, tokens, include_root=False, plain_text=False)</span>
</code></dt>
<dd>
<div class="desc"><p>Create a new CorpusSlice with Documents that contain at least one of the
given tokens.</p>
<p>If <code>plain_text</code> is True, will match <code>tokens</code> against the plain-text
representation of the Document rather than its raw tokens (which might have
undergone various transformations).</p>
<p><code>tokens</code> is canonically an iterable of single tokens, but if <code>plain_text</code> is
set, a search will be done using the literal text of each element, allowing
for exact phrase matching as well.</p>
<p>If <code>include_root</code> is True, will also search the root Corpus for Documents
instead of limiting the search to the current CorpusSlice.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>tokens</code></strong> :&ensp;<code>iterable</code> of <code>str</code></dt>
<dd>A list of the tokens to search Documents for</dd>
<dt><strong><code>include_root</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>Whether or not to search the root Corpus as well</dd>
<dt><strong><code>plain_text</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>Whether or not to search the plain-text representation of the Document
rather than its tokenised form</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code><a title="ignis.corpus.CorpusSlice" href="#ignis.corpus.CorpusSlice">CorpusSlice</a></code></dt>
<dd>&nbsp;</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def slice_by_tokens(self, tokens, include_root=False, plain_text=False):
    &#34;&#34;&#34;
    Create a new CorpusSlice with Documents that contain at least one of the
    given tokens.

    If `plain_text` is True, will match `tokens` against the plain-text
    representation of the Document rather than its raw tokens (which might have
    undergone various transformations).

    `tokens` is canonically an iterable of single tokens, but if `plain_text` is
    set, a search will be done using the literal text of each element, allowing
    for exact phrase matching as well.

    If `include_root` is True, will also search the root Corpus for Documents
    instead of limiting the search to the current CorpusSlice.

    Parameters
    ----------
    tokens: iterable of str
        A list of the tokens to search Documents for
    include_root: bool, optional
        Whether or not to search the root Corpus as well
    plain_text: bool, optional
        Whether or not to search the plain-text representation of the Document
        rather than its tokenised form

    Returns
    -------
    CorpusSlice
    &#34;&#34;&#34;
    # Sanity check
    if type(tokens) is str:
        raise RuntimeWarning(
            &#34;Received a single string instead of an iterable of token &#34;
            &#34;strings -- You probably did not intend to do this.&#34;
        )

    if include_root:
        search_docs = self.root.documents
    else:
        search_docs = self.documents

    # By-token search matches tokens directly
    search_tokens = set(tokens)

    # Plain-text search performs a regex text search
    search_patterns = [
        re.compile(fr&#34;(\s|^){re.escape(token)}(\s|$)&#34;) for token in tokens
    ]

    found_doc_ids = []
    for doc_id, doc in search_docs.items():
        if plain_text:
            doc_text = doc.plain_text

            found_pattern = False
            for pattern in search_patterns:
                if pattern.search(doc_text):
                    found_pattern = True
                    break

            if found_pattern:
                found_doc_ids.append(doc_id)

        else:
            doc_tokens = set(doc.tokens)
            if len(search_tokens &amp; doc_tokens) &gt; 0:
                found_doc_ids.append(doc_id)

    return self.slice_by_ids(found_doc_ids)</code></pre>
</details>
</dd>
<dt id="ignis.corpus.CorpusSlice.slice_filter"><code class="name flex">
<span>def <span class="ident">slice_filter</span></span>(<span>self, filter_fn, include_root=False)</span>
</code></dt>
<dd>
<div class="desc"><p>Returns a new CorpusSlice with the Documents that <code>filter_fn</code> returns True for.</p>
<p><code>filter_fn</code> receives one argument, a single Document in this CorpusSlice.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>filter_fn</code></strong> :&ensp;<code>fn</code></dt>
<dd>The filter function</dd>
<dt><strong><code>include_root</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>Whether or not to search the root Corpus as well</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code><a title="ignis.corpus.CorpusSlice" href="#ignis.corpus.CorpusSlice">CorpusSlice</a></code></dt>
<dd>&nbsp;</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def slice_filter(self, filter_fn, include_root=False):
    &#34;&#34;&#34;
    Returns a new CorpusSlice with the Documents that `filter_fn` returns True for.

    `filter_fn` receives one argument, a single Document in this CorpusSlice.

    Parameters
    ----------
    filter_fn: fn
        The filter function
    include_root: bool, optional
        Whether or not to search the root Corpus as well

    Returns
    -------
    CorpusSlice
    &#34;&#34;&#34;
    if include_root:
        search_docs = self.root.documents
    else:
        search_docs = self.documents

    filtered_doc_ids = []
    for doc_id, doc in search_docs.items():
        if filter_fn(doc):
            filtered_doc_ids.append(doc_id)

    return self.slice_by_ids(filtered_doc_ids)</code></pre>
</details>
</dd>
<dt id="ignis.corpus.CorpusSlice.slice_without_tokens"><code class="name flex">
<span>def <span class="ident">slice_without_tokens</span></span>(<span>self, tokens, include_root=False, plain_text=False)</span>
</code></dt>
<dd>
<div class="desc"><p>Returns a new CorpusSlice with the Documents that contain <code>tokens</code> removed.</p>
<p>If <code>plain_text</code> is True, will match <code>tokens</code> against the plain-text
representation of the Document rather than its raw tokens (which might have
undergone various transformations).</p>
<p><code>tokens</code> is canonically an iterable of single tokens, but if <code>plain_text</code> is
set, a search will be done using the literal text of each element, allowing
for exact phrase matching as well.</p>
<p>If <code>include_root</code> is True, will also search the root Corpus for Documents
instead of limiting the search to the current CorpusSlice.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>tokens</code></strong> :&ensp;<code>iterable</code> of <code>str</code></dt>
<dd>The tokens (or phrases) to remove</dd>
<dt><strong><code>include_root</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>Whether or not to search the root Corpus as well</dd>
<dt><strong><code>plain_text</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>Whether or not to search the plain-text representation of the Document
rather than its tokenised form</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code><a title="ignis.corpus.CorpusSlice" href="#ignis.corpus.CorpusSlice">CorpusSlice</a></code></dt>
<dd>&nbsp;</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def slice_without_tokens(self, tokens, include_root=False, plain_text=False):
    &#34;&#34;&#34;
    Returns a new CorpusSlice with the Documents that contain `tokens` removed.

    If `plain_text` is True, will match `tokens` against the plain-text
    representation of the Document rather than its raw tokens (which might have
    undergone various transformations).

    `tokens` is canonically an iterable of single tokens, but if `plain_text` is
    set, a search will be done using the literal text of each element, allowing
    for exact phrase matching as well.

    If `include_root` is True, will also search the root Corpus for Documents
    instead of limiting the search to the current CorpusSlice.

    Parameters
    ----------
    tokens: iterable of str
        The tokens (or phrases) to remove
    include_root: bool, optional
        Whether or not to search the root Corpus as well
    plain_text: bool, optional
        Whether or not to search the plain-text representation of the Document
        rather than its tokenised form

    Returns
    -------
    CorpusSlice
    &#34;&#34;&#34;
    # Sanity check
    if type(tokens) is str:
        raise RuntimeWarning(
            &#34;Received a single string instead of an iterable of token &#34;
            &#34;strings -- You probably did not intend to do this.&#34;
        )

    if include_root:
        search_docs = self.root.documents
    else:
        search_docs = self.documents

    # By-token search matches tokens directly
    search_tokens = set(tokens)

    # Plain-text search performs a regex text search
    search_patterns = [
        re.compile(fr&#34;(\s|^){re.escape(token)}(\s|$)&#34;) for token in tokens
    ]

    filtered_doc_ids = []
    for doc_id, doc in search_docs.items():
        if plain_text:
            doc_text = doc.plain_text

            found_pattern = False
            for pattern in search_patterns:
                if pattern.search(doc_text):
                    found_pattern = True
                    break

            if not found_pattern:
                filtered_doc_ids.append(doc_id)

        else:
            doc_tokens = set(doc.tokens)
            if len(search_tokens &amp; doc_tokens) == 0:
                filtered_doc_ids.append(doc_id)

    return self.slice_by_ids(filtered_doc_ids)</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="ignis.corpus.Document"><code class="flex name class">
<span>class <span class="ident">Document</span></span>
<span>(</span><span>tokens, metadata, display_str, plain_text=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Documents hold the textual content of each file in the Corpus, as well as any
relevant metadata.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>tokens</code></strong> :&ensp;<code>iterable</code> of <code>str</code></dt>
<dd>The individual content tokens in the given document; will be fed directly
into the various topic modelling algorithms. Assumed to have already
undergone any necessary munging.</dd>
<dt><strong><code>metadata</code></strong> :&ensp;<code>dict</code></dt>
<dd>A general-purpose dictionary containing any metadata the user wants to
track.</dd>
<dt><strong><code>display_str</code></strong> :&ensp;<code>str</code></dt>
<dd>The content of the document, as a single string containing any necessary
markup or other formatting for human-readable display. By default,
<code>display_str</code> is assumed to contain a HTML representation of the document (
e.g., when the document is rendered in <code>ignis.aurum.nb_explore_topics()</code>),
but a custom display function can be passed where necessary.</dd>
<dt><strong><code>plain_text</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>The full text of the given document as a single normalised string. If
<code>plain_text</code> is None, <code>display_str</code> is assumed to contain a HTML representation
of the document, and a corresponding plain-text representation is
automatically generated via BeautifulSoup when the attribute is first accessed.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class Document(object):
    &#34;&#34;&#34;
    Documents hold the textual content of each file in the Corpus, as well as any
    relevant metadata.

    Parameters
    ----------
    tokens: iterable of str
        The individual content tokens in the given document; will be fed directly
        into the various topic modelling algorithms. Assumed to have already
        undergone any necessary munging.
    metadata: dict
        A general-purpose dictionary containing any metadata the user wants to
        track.
    display_str: str
        The content of the document, as a single string containing any necessary
        markup or other formatting for human-readable display. By default,
        `display_str` is assumed to contain a HTML representation of the document (
        e.g., when the document is rendered in `ignis.aurum.nb_explore_topics()`),
        but a custom display function can be passed where necessary.
    plain_text: str, optional
        The full text of the given document as a single normalised string. If
        `plain_text` is None, `display_str` is assumed to contain a HTML representation
        of the document, and a corresponding plain-text representation is
        automatically generated via BeautifulSoup when the attribute is first accessed.
    &#34;&#34;&#34;

    # Let&#39;s make Document IDs deterministic on their data, so that multiple runs of a
    # Corpus creation script don&#39;t generate different IDs.
    # We will create a UUID5 for each Document against this fixed namespace:
    ignis_uuid_namespace = uuid.UUID(&#34;58ca78f2-0347-4b96-b2e7-63796bf87889&#34;)

    def __init__(self, tokens, metadata, display_str, plain_text=None):
        self.tokens = tokens
        self.metadata = metadata
        self.display_str = display_str
        self.plain_text = plain_text

        data = f&#34;{tokens}{metadata}{display_str}&#34;
        self.id = uuid.uuid5(Document.ignis_uuid_namespace, data)

    def __str__(self):
        metadata = json.dumps(self.metadata, indent=2)

        truncated = []
        for line in metadata.splitlines():
            if len(line) &gt; 120:
                truncated.append(f&#34;{line[:120]}...&#34;)
            else:
                truncated.append(line)
        metadata = &#34;\n&#34;.join(truncated)

        return f&#34;ID: {self.id}\n\nMetadata: {metadata}\n\n&#34; f&#34;{self.display_str}&#34;

    def __getattribute__(self, item):
        if item == &#34;plain_text&#34; and object.__getattribute__(self, &#34;plain_text&#34;) is None:
            # There is no `plain_text` set for this document; assume that
            # `display_str` contains a HTML representation of the document.
            soup = BeautifulSoup(self.display_str, &#34;lxml&#34;)

            # The text returned by BeautifulSoup might contain whitespace --
            # Concatenate, split, and concatenate again to normalise the spacing
            self.plain_text = &#34; &#34;.join(soup.get_text().split())
            return self.plain_text
        return object.__getattribute__(self, item)</code></pre>
</details>
<h3>Class variables</h3>
<dl>
<dt id="ignis.corpus.Document.ignis_uuid_namespace"><code class="name">var <span class="ident">ignis_uuid_namespace</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<div style="padding: 1em 0.5em">
<a href="/ignis">
<div style="display: flex; align-items: center">
<img src="logo.png" alt="Ignis" height="50"/>
<span style="font-size: 2em; font-weight: 700; margin-left: 0.75em">Ignis</span>
</div>
</a>
</div>
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="ignis" href="index.html">ignis</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="ignis.corpus.load_corpus" href="#ignis.corpus.load_corpus">load_corpus</a></code></li>
<li><code><a title="ignis.corpus.load_slice" href="#ignis.corpus.load_slice">load_slice</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="ignis.corpus.Corpus" href="#ignis.corpus.Corpus">Corpus</a></code></h4>
<ul class="">
<li><code><a title="ignis.corpus.Corpus.add_doc" href="#ignis.corpus.Corpus.add_doc">add_doc</a></code></li>
<li><code><a title="ignis.corpus.Corpus.save" href="#ignis.corpus.Corpus.save">save</a></code></li>
<li><code><a title="ignis.corpus.Corpus.slice_full" href="#ignis.corpus.Corpus.slice_full">slice_full</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="ignis.corpus.CorpusSlice" href="#ignis.corpus.CorpusSlice">CorpusSlice</a></code></h4>
<ul class="">
<li><code><a title="ignis.corpus.CorpusSlice.concat" href="#ignis.corpus.CorpusSlice.concat">concat</a></code></li>
<li><code><a title="ignis.corpus.CorpusSlice.document_ids" href="#ignis.corpus.CorpusSlice.document_ids">document_ids</a></code></li>
<li><code><a title="ignis.corpus.CorpusSlice.get_document" href="#ignis.corpus.CorpusSlice.get_document">get_document</a></code></li>
<li><code><a title="ignis.corpus.CorpusSlice.nb_explore" href="#ignis.corpus.CorpusSlice.nb_explore">nb_explore</a></code></li>
<li><code><a title="ignis.corpus.CorpusSlice.save" href="#ignis.corpus.CorpusSlice.save">save</a></code></li>
<li><code><a title="ignis.corpus.CorpusSlice.slice_by_ids" href="#ignis.corpus.CorpusSlice.slice_by_ids">slice_by_ids</a></code></li>
<li><code><a title="ignis.corpus.CorpusSlice.slice_by_tokens" href="#ignis.corpus.CorpusSlice.slice_by_tokens">slice_by_tokens</a></code></li>
<li><code><a title="ignis.corpus.CorpusSlice.slice_filter" href="#ignis.corpus.CorpusSlice.slice_filter">slice_filter</a></code></li>
<li><code><a title="ignis.corpus.CorpusSlice.slice_without_tokens" href="#ignis.corpus.CorpusSlice.slice_without_tokens">slice_without_tokens</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="ignis.corpus.Document" href="#ignis.corpus.Document">Document</a></code></h4>
<ul class="">
<li><code><a title="ignis.corpus.Document.ignis_uuid_namespace" href="#ignis.corpus.Document.ignis_uuid_namespace">ignis_uuid_namespace</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.9.2</a>.</p>
</footer>
</body>
</html>