<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.9.2" />
<title>ignis.models.base API documentation</title>
<meta name="description" content="" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">import ignis.corpus


class BaseModel:
    &#34;&#34;&#34;
    The base class for all Ignis models.

    Implemented child classes have the freedom to define their own default values for
    each method.

    NOTE: All Ignis models should have topic IDs that start from 1 and not 0;
    i.e., they should be in range(1, num_topics + 1)

    Parameters
    ----------
    corpus_slice: ignis.corpus.CorpusSlice
        The CorpusSlice to train the model on
    options: dict, optional
        Model-specific options
    &#34;&#34;&#34;

    def __init__(self, corpus_slice, options=None):
        # Save a reference to the CorpusSlice we are modelling over
        self.corpus_slice = corpus_slice

        # Unique model type identifier for saving/loading results
        self.model_type = &#34;&lt;set_me&gt;&#34;

        # Model-specific options
        if options is None:
            options = {}
        self.options = options

        # The actual model, as created by the external topic modelling library
        self.model = None

    def get_num_topics(self):
        &#34;&#34;&#34;
        Returns
        -------
        int
            The number of topics in the trained model
        &#34;&#34;&#34;
        pass

    def get_topic_words(self, topic_id, top_n):
        &#34;&#34;&#34;
        NOTE: `topic_id` should start from 1 and not 0;
        i.e., it should be in `range(1, len(topics) + 1)`

        Parameters
        ----------
        topic_id
        top_n

        Returns
        -------
        iterable
            The `top_n` words in the topic `topic_id`, as a list of (&lt;word:str&gt;,
            &lt;probability:float&gt;)
        &#34;&#34;&#34;
        pass

    def get_topic_documents(self, topic_id, within_top_n):
        &#34;&#34;&#34;
        Find Documents that have Topic `topic_id` within its `n` most probable topics.

        Because topics are distributions over terms and documents are distributions
        over topics, documents don&#39;t belong to individual topics per se -- As such,
        we can consider a document to &#34;belong&#34; to a topic if it that topic is one of
        the `n` most probable topics for the document.

        This is especially significant if a term weighting scheme is used, because
        the most frequent words (i.e., what we usually consider stopwords) tend to be
        gathered into one or two topics, and we don&#39;t want to rule out a document if
        its single most probable topic is the stopword topic.

        NOTE: `topic_id` should start from 1 and not 0;
        i.e., it should be in `range(1, len(topics) + 1)`

        Parameters
        ----------
        topic_id
        within_top_n

        Returns
        -------
        iterable of tuples
            A list of tuples (&lt;Document ID&gt;, &lt;topic_id probability&gt;)
        &#34;&#34;&#34;
        pass

    def get_document_topics(self, doc_id, top_n):
        &#34;&#34;&#34;
        Get the top `n` most probable topics for the Document with the given ID.

        Children must accept either a string or UUID for `doc_id`.

        NOTE: The topic IDs in the results start from 1 and not 0.

        Parameters
        ----------
        doc_id: str or uuid.UUID
        top_n

        Returns
        -------
        iterable of tuples
            A list of tuples (&lt;topic ID&gt;, &lt;probability&gt;)
        &#34;&#34;&#34;
        pass

    def get_document_top_topic(self, doc_id):
        &#34;&#34;&#34;
        Get the topic with the highest probability for the given document

        Parameters
        ----------
        doc_id

        Returns
        -------
        tuple
            A single tuple (&lt;topic ID&gt;, &lt;probability&gt;)
        &#34;&#34;&#34;
        pass

    def get_coherence(self, coherence, top_n, window_size, processes):
        &#34;&#34;&#34;
        Use Gensim&#39;s `models.coherencemodel` to get a coherence score for a trained
        model.

        Parameters
        ----------
        coherence: {&#34;u_mass&#34;, &#34;c_v&#34;, &#34;c_uci&#34;, &#34;c_npmi&#34;}
            Coherence measure to calculate
        top_n: int
            Number of top words to extract from each topic
        window_size: int
            Window size for &#34;c_v&#34;, &#34;c_uci&#34;, and &#34;c_npmi&#34;
        processes: int
            Number of worker processes

        Returns
        -------
        float
        &#34;&#34;&#34;
        pass</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="ignis.models.base.BaseModel"><code class="flex name class">
<span>class <span class="ident">BaseModel</span></span>
<span>(</span><span>corpus_slice, options=None)</span>
</code></dt>
<dd>
<div class="desc"><p>The base class for all Ignis models.</p>
<p>Implemented child classes have the freedom to define their own default values for
each method.</p>
<p>NOTE: All Ignis models should have topic IDs that start from 1 and not 0;
i.e., they should be in range(1, num_topics + 1)</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>corpus_slice</code></strong> :&ensp;<code><a title="ignis.corpus.CorpusSlice" href="../corpus.html#ignis.corpus.CorpusSlice">CorpusSlice</a></code></dt>
<dd>The CorpusSlice to train the model on</dd>
<dt><strong><code>options</code></strong> :&ensp;<code>dict</code>, optional</dt>
<dd>Model-specific options</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class BaseModel:
    &#34;&#34;&#34;
    The base class for all Ignis models.

    Implemented child classes have the freedom to define their own default values for
    each method.

    NOTE: All Ignis models should have topic IDs that start from 1 and not 0;
    i.e., they should be in range(1, num_topics + 1)

    Parameters
    ----------
    corpus_slice: ignis.corpus.CorpusSlice
        The CorpusSlice to train the model on
    options: dict, optional
        Model-specific options
    &#34;&#34;&#34;

    def __init__(self, corpus_slice, options=None):
        # Save a reference to the CorpusSlice we are modelling over
        self.corpus_slice = corpus_slice

        # Unique model type identifier for saving/loading results
        self.model_type = &#34;&lt;set_me&gt;&#34;

        # Model-specific options
        if options is None:
            options = {}
        self.options = options

        # The actual model, as created by the external topic modelling library
        self.model = None

    def get_num_topics(self):
        &#34;&#34;&#34;
        Returns
        -------
        int
            The number of topics in the trained model
        &#34;&#34;&#34;
        pass

    def get_topic_words(self, topic_id, top_n):
        &#34;&#34;&#34;
        NOTE: `topic_id` should start from 1 and not 0;
        i.e., it should be in `range(1, len(topics) + 1)`

        Parameters
        ----------
        topic_id
        top_n

        Returns
        -------
        iterable
            The `top_n` words in the topic `topic_id`, as a list of (&lt;word:str&gt;,
            &lt;probability:float&gt;)
        &#34;&#34;&#34;
        pass

    def get_topic_documents(self, topic_id, within_top_n):
        &#34;&#34;&#34;
        Find Documents that have Topic `topic_id` within its `n` most probable topics.

        Because topics are distributions over terms and documents are distributions
        over topics, documents don&#39;t belong to individual topics per se -- As such,
        we can consider a document to &#34;belong&#34; to a topic if it that topic is one of
        the `n` most probable topics for the document.

        This is especially significant if a term weighting scheme is used, because
        the most frequent words (i.e., what we usually consider stopwords) tend to be
        gathered into one or two topics, and we don&#39;t want to rule out a document if
        its single most probable topic is the stopword topic.

        NOTE: `topic_id` should start from 1 and not 0;
        i.e., it should be in `range(1, len(topics) + 1)`

        Parameters
        ----------
        topic_id
        within_top_n

        Returns
        -------
        iterable of tuples
            A list of tuples (&lt;Document ID&gt;, &lt;topic_id probability&gt;)
        &#34;&#34;&#34;
        pass

    def get_document_topics(self, doc_id, top_n):
        &#34;&#34;&#34;
        Get the top `n` most probable topics for the Document with the given ID.

        Children must accept either a string or UUID for `doc_id`.

        NOTE: The topic IDs in the results start from 1 and not 0.

        Parameters
        ----------
        doc_id: str or uuid.UUID
        top_n

        Returns
        -------
        iterable of tuples
            A list of tuples (&lt;topic ID&gt;, &lt;probability&gt;)
        &#34;&#34;&#34;
        pass

    def get_document_top_topic(self, doc_id):
        &#34;&#34;&#34;
        Get the topic with the highest probability for the given document

        Parameters
        ----------
        doc_id

        Returns
        -------
        tuple
            A single tuple (&lt;topic ID&gt;, &lt;probability&gt;)
        &#34;&#34;&#34;
        pass

    def get_coherence(self, coherence, top_n, window_size, processes):
        &#34;&#34;&#34;
        Use Gensim&#39;s `models.coherencemodel` to get a coherence score for a trained
        model.

        Parameters
        ----------
        coherence: {&#34;u_mass&#34;, &#34;c_v&#34;, &#34;c_uci&#34;, &#34;c_npmi&#34;}
            Coherence measure to calculate
        top_n: int
            Number of top words to extract from each topic
        window_size: int
            Window size for &#34;c_v&#34;, &#34;c_uci&#34;, and &#34;c_npmi&#34;
        processes: int
            Number of worker processes

        Returns
        -------
        float
        &#34;&#34;&#34;
        pass</code></pre>
</details>
<h3>Subclasses</h3>
<ul class="hlist">
<li><a title="ignis.models.hdp.HDPModel" href="hdp.html#ignis.models.hdp.HDPModel">HDPModel</a></li>
<li><a title="ignis.models.lda.LDAModel" href="lda.html#ignis.models.lda.LDAModel">LDAModel</a></li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="ignis.models.base.BaseModel.get_coherence"><code class="name flex">
<span>def <span class="ident">get_coherence</span></span>(<span>self, coherence, top_n, window_size, processes)</span>
</code></dt>
<dd>
<div class="desc"><p>Use Gensim's <code>models.coherencemodel</code> to get a coherence score for a trained
model.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>coherence</code></strong> :&ensp;<code>{"u_mass", "c_v", "c_uci", "c_npmi"}</code></dt>
<dd>Coherence measure to calculate</dd>
<dt><strong><code>top_n</code></strong> :&ensp;<code>int</code></dt>
<dd>Number of top words to extract from each topic</dd>
<dt><strong><code>window_size</code></strong> :&ensp;<code>int</code></dt>
<dd>Window size for "c_v", "c_uci", and "c_npmi"</dd>
<dt><strong><code>processes</code></strong> :&ensp;<code>int</code></dt>
<dd>Number of worker processes</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>float</code></dt>
<dd>&nbsp;</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_coherence(self, coherence, top_n, window_size, processes):
    &#34;&#34;&#34;
    Use Gensim&#39;s `models.coherencemodel` to get a coherence score for a trained
    model.

    Parameters
    ----------
    coherence: {&#34;u_mass&#34;, &#34;c_v&#34;, &#34;c_uci&#34;, &#34;c_npmi&#34;}
        Coherence measure to calculate
    top_n: int
        Number of top words to extract from each topic
    window_size: int
        Window size for &#34;c_v&#34;, &#34;c_uci&#34;, and &#34;c_npmi&#34;
    processes: int
        Number of worker processes

    Returns
    -------
    float
    &#34;&#34;&#34;
    pass</code></pre>
</details>
</dd>
<dt id="ignis.models.base.BaseModel.get_document_top_topic"><code class="name flex">
<span>def <span class="ident">get_document_top_topic</span></span>(<span>self, doc_id)</span>
</code></dt>
<dd>
<div class="desc"><p>Get the topic with the highest probability for the given document</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>doc_id</code></strong></dt>
<dd>&nbsp;</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>tuple</code></dt>
<dd>A single tuple (<topic ID>, <probability>)</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_document_top_topic(self, doc_id):
    &#34;&#34;&#34;
    Get the topic with the highest probability for the given document

    Parameters
    ----------
    doc_id

    Returns
    -------
    tuple
        A single tuple (&lt;topic ID&gt;, &lt;probability&gt;)
    &#34;&#34;&#34;
    pass</code></pre>
</details>
</dd>
<dt id="ignis.models.base.BaseModel.get_document_topics"><code class="name flex">
<span>def <span class="ident">get_document_topics</span></span>(<span>self, doc_id, top_n)</span>
</code></dt>
<dd>
<div class="desc"><p>Get the top <code>n</code> most probable topics for the Document with the given ID.</p>
<p>Children must accept either a string or UUID for <code>doc_id</code>.</p>
<p>NOTE: The topic IDs in the results start from 1 and not 0.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>doc_id</code></strong> :&ensp;<code>str</code> or <code>uuid.UUID</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>top_n</code></strong></dt>
<dd>&nbsp;</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>iterable</code> of <code>tuples</code></dt>
<dd>A list of tuples (<topic ID>, <probability>)</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_document_topics(self, doc_id, top_n):
    &#34;&#34;&#34;
    Get the top `n` most probable topics for the Document with the given ID.

    Children must accept either a string or UUID for `doc_id`.

    NOTE: The topic IDs in the results start from 1 and not 0.

    Parameters
    ----------
    doc_id: str or uuid.UUID
    top_n

    Returns
    -------
    iterable of tuples
        A list of tuples (&lt;topic ID&gt;, &lt;probability&gt;)
    &#34;&#34;&#34;
    pass</code></pre>
</details>
</dd>
<dt id="ignis.models.base.BaseModel.get_num_topics"><code class="name flex">
<span>def <span class="ident">get_num_topics</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><h2 id="returns">Returns</h2>
<dl>
<dt><code>int</code></dt>
<dd>The number of topics in the trained model</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_num_topics(self):
    &#34;&#34;&#34;
    Returns
    -------
    int
        The number of topics in the trained model
    &#34;&#34;&#34;
    pass</code></pre>
</details>
</dd>
<dt id="ignis.models.base.BaseModel.get_topic_documents"><code class="name flex">
<span>def <span class="ident">get_topic_documents</span></span>(<span>self, topic_id, within_top_n)</span>
</code></dt>
<dd>
<div class="desc"><p>Find Documents that have Topic <code>topic_id</code> within its <code>n</code> most probable topics.</p>
<p>Because topics are distributions over terms and documents are distributions
over topics, documents don't belong to individual topics per se &ndash; As such,
we can consider a document to "belong" to a topic if it that topic is one of
the <code>n</code> most probable topics for the document.</p>
<p>This is especially significant if a term weighting scheme is used, because
the most frequent words (i.e., what we usually consider stopwords) tend to be
gathered into one or two topics, and we don't want to rule out a document if
its single most probable topic is the stopword topic.</p>
<p>NOTE: <code>topic_id</code> should start from 1 and not 0;
i.e., it should be in <code>range(1, len(topics) + 1)</code></p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>topic_id</code></strong></dt>
<dd>&nbsp;</dd>
<dt><strong><code>within_top_n</code></strong></dt>
<dd>&nbsp;</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>iterable</code> of <code>tuples</code></dt>
<dd>A list of tuples (<Document ID>, <topic_id probability>)</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_topic_documents(self, topic_id, within_top_n):
    &#34;&#34;&#34;
    Find Documents that have Topic `topic_id` within its `n` most probable topics.

    Because topics are distributions over terms and documents are distributions
    over topics, documents don&#39;t belong to individual topics per se -- As such,
    we can consider a document to &#34;belong&#34; to a topic if it that topic is one of
    the `n` most probable topics for the document.

    This is especially significant if a term weighting scheme is used, because
    the most frequent words (i.e., what we usually consider stopwords) tend to be
    gathered into one or two topics, and we don&#39;t want to rule out a document if
    its single most probable topic is the stopword topic.

    NOTE: `topic_id` should start from 1 and not 0;
    i.e., it should be in `range(1, len(topics) + 1)`

    Parameters
    ----------
    topic_id
    within_top_n

    Returns
    -------
    iterable of tuples
        A list of tuples (&lt;Document ID&gt;, &lt;topic_id probability&gt;)
    &#34;&#34;&#34;
    pass</code></pre>
</details>
</dd>
<dt id="ignis.models.base.BaseModel.get_topic_words"><code class="name flex">
<span>def <span class="ident">get_topic_words</span></span>(<span>self, topic_id, top_n)</span>
</code></dt>
<dd>
<div class="desc"><p>NOTE: <code>topic_id</code> should start from 1 and not 0;
i.e., it should be in <code>range(1, len(topics) + 1)</code></p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>topic_id</code></strong></dt>
<dd>&nbsp;</dd>
<dt><strong><code>top_n</code></strong></dt>
<dd>&nbsp;</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>iterable</code></dt>
<dd>The <code>top_n</code> words in the topic <code>topic_id</code>, as a list of (<word:str>,
<probability:float>)</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_topic_words(self, topic_id, top_n):
    &#34;&#34;&#34;
    NOTE: `topic_id` should start from 1 and not 0;
    i.e., it should be in `range(1, len(topics) + 1)`

    Parameters
    ----------
    topic_id
    top_n

    Returns
    -------
    iterable
        The `top_n` words in the topic `topic_id`, as a list of (&lt;word:str&gt;,
        &lt;probability:float&gt;)
    &#34;&#34;&#34;
    pass</code></pre>
</details>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<div style="padding: 1em 0.5em">
<a href="/ignis">
<div style="display: flex; align-items: center">
<img src="logo.png" alt="Ignis" height="50"/>
<span style="font-size: 2em; font-weight: 700; margin-left: 0.75em">Ignis</span>
</div>
</a>
</div>
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="ignis.models" href="index.html">ignis.models</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="ignis.models.base.BaseModel" href="#ignis.models.base.BaseModel">BaseModel</a></code></h4>
<ul class="">
<li><code><a title="ignis.models.base.BaseModel.get_coherence" href="#ignis.models.base.BaseModel.get_coherence">get_coherence</a></code></li>
<li><code><a title="ignis.models.base.BaseModel.get_document_top_topic" href="#ignis.models.base.BaseModel.get_document_top_topic">get_document_top_topic</a></code></li>
<li><code><a title="ignis.models.base.BaseModel.get_document_topics" href="#ignis.models.base.BaseModel.get_document_topics">get_document_topics</a></code></li>
<li><code><a title="ignis.models.base.BaseModel.get_num_topics" href="#ignis.models.base.BaseModel.get_num_topics">get_num_topics</a></code></li>
<li><code><a title="ignis.models.base.BaseModel.get_topic_documents" href="#ignis.models.base.BaseModel.get_topic_documents">get_topic_documents</a></code></li>
<li><code><a title="ignis.models.base.BaseModel.get_topic_words" href="#ignis.models.base.BaseModel.get_topic_words">get_topic_words</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.9.2</a>.</p>
</footer>
</body>
</html>