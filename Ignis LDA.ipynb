{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ignis: LDA\n",
    "============\n",
    "\n",
    "Welcome to the Ignis LDA Modelling Template.\n",
    "\n",
    "Use this Jupyter notebook as a demo and starting point for modelling and exploring your own data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-18T07:17:41.597967Z",
     "start_time": "2021-06-18T07:17:41.216082Z"
    }
   },
   "outputs": [],
   "source": [
    "import ignis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model training (LDA)\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load from an `ignis.Corpus`, add the processed docs to an LDA model, and train it.\n",
    "\n",
    "Because LDA is a probabilistic algorithm, the model's random seed and parallelisation options can both affect results, so setting the seed and number of workers is necessary for reproducibility.\n",
    "\n",
    "(Most users don't need to be too concerned about this: to be safe, Ignis sets both parameters to initial default values, but these can be overridden by advanced users as necessary.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-18T07:17:44.590353Z",
     "start_time": "2021-06-18T07:17:41.959687Z"
    }
   },
   "outputs": [],
   "source": [
    "corpus = ignis.load_corpus(\"data/bbc.corpus\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The LDA implementation also provides a number of other options that can be changed by the user as necessary, but for most general cases, we can stick with the default values.\n",
    "\n",
    "See the library docs for more information about the available options."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-04T08:55:53.807676Z",
     "start_time": "2021-06-04T08:55:53.794560Z"
    }
   },
   "outputs": [],
   "source": [
    "# Setting an empty dictionary here uses the ignis-provided defaults for all options.\n",
    "model_options = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of topics for the algorithm to infer, `k`, needs to be set in advance, but a convenience method, `ignis.suggest_num_topics()`, can be used to suggest a suitable initial setting heuristically. (Specifically, it trains a number of mini-models and assesses how well the top `n` words of each topic in each model are related.)\n",
    "\n",
    "Because this is only a _suggested_ initial setting, users are free to ignore it and experiment with different manual values of `k` instead to see how the results change accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-04T08:56:06.477691Z",
     "start_time": "2021-06-04T08:55:53.809560Z"
    }
   },
   "outputs": [],
   "source": [
    "# Here, we override the `k` option with the output of `ignis.suggest_num_topics()`.\n",
    "model_options[\"k\"] = ignis.suggest_num_topics(corpus, model_options=model_options)\n",
    "\n",
    "# To specify your own value for `k`, use something liek the following line instead:\n",
    "# model_options[\"k\"] = 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then train the actual final topic model with the configured value of `k`..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-04T08:56:20.690008Z",
     "start_time": "2021-06-04T08:56:06.477691Z"
    }
   },
   "outputs": [],
   "source": [
    "results = ignis.train_model(\n",
    "    corpus,\n",
    "    model_options=model_options,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and show the basic graphical visualisation of the topics that were found:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-04T08:56:20.720844Z",
     "start_time": "2021-06-04T08:56:20.691732Z"
    }
   },
   "outputs": [],
   "source": [
    "results.show_visualisation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exporting visualisations\n",
    "\n",
    "If we want, we can export the visualisations to a separate folder for offline display using the `.export_visualisation()` method.\n",
    "\n",
    "Uncomment and specify a target folder in the cell below, then run the cell and open the exported `visualisation.html` file to view the visualisation.\n",
    "\n",
    "The entire folder can be copied to a different PC to display the visualisation there.\n",
    "\n",
    "If the display PC will not have internet access, set `use_cdn` to `False`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-04T08:56:20.736870Z",
     "start_time": "2021-06-04T08:56:20.723849Z"
    }
   },
   "outputs": [],
   "source": [
    "# results.export_visualisation(\"data/bbc_results\", use_cdn=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving topic modelling results\n",
    "\n",
    "The trained model can be saved to a separate file and loaded on another PC or after a Jupyter notebook restart, negating the need to redo a potentially time-consuming training run.\n",
    "\n",
    "N.B.: The saving/loading of topic modelling results can also take some time, because the full contents of each document in the corpus are also saved to the results file for continued display and iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-04T08:56:20.752851Z",
     "start_time": "2021-06-04T08:56:20.738841Z"
    }
   },
   "outputs": [],
   "source": [
    "# results.save(\"data/bbc.aurum\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of running the modelling steps above on the other PC, the results can then be loaded directly with `ignis.load_results()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-04T09:04:42.416036Z",
     "start_time": "2021-06-04T09:04:41.225540Z"
    }
   },
   "outputs": [],
   "source": [
    "# import ignis\n",
    "# results = ignis.load_results(\"data/bbc.aurum\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the automated labeller\n",
    "\n",
    "The automated labeller tries to come up with a few key terms that describe each topic. Its results may provide a slightly different perspective from the main model output (which is simply a list of the most probable terms for each topic).\n",
    "\n",
    "If the automated labeller is initialised using the `.init_labeller()` function below, its suggestions will automatically be shown in the `.nb_explore_topics()` widget in the next section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-04T09:04:44.513862Z",
     "start_time": "2021-06-04T09:04:43.863953Z"
    }
   },
   "outputs": [],
   "source": [
    "results.init_labeller(\"tomotopy\", verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring documents that \"belong\" to a given topic\n",
    "\n",
    "Because topics are distributions over words and documents are *distributions* over topics, documents don't belong to individual topics per se; every topic is represented in every document with some probability.\n",
    "\n",
    "We therefore have to specify how many of the document's top `n` topics we want to check for the actual topic we're interested in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-04T09:04:45.933583Z",
     "start_time": "2021-06-04T09:04:45.817532Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "results.nb_explore_topics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Slicing and iteration\n",
    "--------\n",
    "After seeing what the main topics might be, we can slice the initial corpus further and re-run topic modelling to get better resolution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-01T14:20:36.538106Z",
     "start_time": "2021-06-01T14:20:36.514113Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Try zooming in on a sub-topic\n",
    "sub_slice = results.slice_by_topic(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We might start by checking exactly which documents a slice of the corpus contains, by exploring it directly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-01T14:20:37.196334Z",
     "start_time": "2021-06-01T14:20:37.146339Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# By default, the documents in the slice are put in an arbitrary order.\n",
    "# For advanced users, a custom sort key can be used to change this:\n",
    "# E.g., this one sorts documents by the probability of their top topic instead.\n",
    "# (This gives us the same document order as in the `nb_explore_topics()` widget above.)\n",
    "sub_slice.nb_explore(\n",
    "    doc_sort_key=lambda doc: results.get_document_top_topic(doc.id)[1], reverse=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As before, Ignis can suggest a recommended number of topics to use for LDA, based on the coherence scores of a range of lightly-trained models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-01T14:20:46.990813Z",
     "start_time": "2021-06-01T14:20:38.275533Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Getting a suggested number of topics and retraining the model on the new slice\n",
    "best_k = results.resuggest_num_topics(corpus_slice=sub_slice, verbose=True)\n",
    "sub_model = results.retrain_model(corpus_slice=sub_slice, model_options={\"k\": best_k})\n",
    "sub_model.show_visualisation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-08T03:23:48.733894Z",
     "start_time": "2020-06-08T03:23:46.841220Z"
    }
   },
   "source": [
    "The position of each topic cluster on the graph is not intrinsically informative per se (being simply the result of some specified dimensionality-reducing technique), but if we want we can run the modelling algorithm with a different random seed and see if we get a more nicely-separated set of topics.\n",
    "\n",
    "(We can also override any of the previously set options.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-01T14:20:53.866001Z",
     "start_time": "2021-06-01T14:20:49.331509Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "new_model_options = {\"seed\": 1234567}\n",
    "sub_model_2 = sub_model.retrain_model(model_options=new_model_options)\n",
    "sub_model_2.show_visualisation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The topic words remain more or less consistent across different training runs, even though their positions in the visualisation change when the random seed is changed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-01T14:21:06.724450Z",
     "start_time": "2021-06-01T14:21:06.612463Z"
    }
   },
   "outputs": [],
   "source": [
    "sub_model_2.nb_explore_topics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further slicing and iteration\n",
    "\n",
    "In addition to simply slicing by topic, we can also explicitly search the whole corpus for documents that contain certain tokens, in case we want to be absolutely sure we got all the documents that mention certain words or phrases.\n",
    "\n",
    "References and examples are available on the Ignis documentation site for all the slicing functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-01T14:21:17.889906Z",
     "start_time": "2021-06-01T14:21:08.553999Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Tokens that are related to games, doing a full-text search through the entire corpus (not just within the current results)\n",
    "game_slice = sub_model_2.slice_by_tokens([\"game\", \"games\", \"gaming\"], include_root=True)\n",
    "game_k = sub_model_2.resuggest_num_topics(game_slice, verbose=True, start_k=3)\n",
    "game_model = sub_model_2.retrain_model(game_slice, model_options={\"k\": game_k})\n",
    "game_model.show_visualisation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-01T14:21:18.047911Z",
     "start_time": "2021-06-01T14:21:17.892905Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "game_model.nb_explore_topics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manipulating the stop word list\n",
    "\n",
    "If you want to add or remove words from the stop word list at run-time, you can use the `add_stop_word()` and `remove_stop_word()` methods on a slice (or their plural versions, `add_stop_words()` and `remove_stop_words()`) to do so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-01T14:21:35.614864Z",
     "start_time": "2021-06-01T14:21:26.875642Z"
    }
   },
   "outputs": [],
   "source": [
    "# If we decide that certain tokens do not contribute to our `game_slice` model:\n",
    "game_slice.add_stop_words([\"try\", \"i am\", \"people\"])\n",
    "game_k = game_model.resuggest_num_topics(game_slice, verbose=True, start_k=3)\n",
    "game_model = game_model.retrain_model(game_slice, model_options={\"k\": game_k})\n",
    "game_model.show_visualisation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In these new results above, the tokens we added to the stop word list no longer appear in the topic models.\n",
    "\n",
    "**N.B.:** These stop words are controlled at the root Corpus level, so any stop words that are added or removed will apply to _all_ slices that originate from the same initial Corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}