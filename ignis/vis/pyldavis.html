<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.9.2" />
<title>ignis.vis.pyldavis API documentation</title>
<meta name="description" content="" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">import pathlib
import shutil
import threading
import time
import warnings

try:
    # Don&#39;t depend fully on a Jupyter environment, in case the user wants to create
    # headless visualisations
    from IPython.core.display import display, HTML
except ModuleNotFoundError:
    pass

# We monkey patch pyLDAvis to optimise various pandas calculations below
from joblib import Parallel, delayed

import ignis.util

pyLDAvis = ignis.util.LazyLoader(&#34;pyLDAvis&#34;)
np = ignis.util.LazyLoader(&#34;numpy&#34;)
pd = ignis.util.LazyLoader(&#34;pandas&#34;)

# noinspection PyProtectedMember
_prepare = pyLDAvis._prepare


def show_visualisation(vis_data):
    &#34;&#34;&#34;
    Display the pyLDAvis visualisation for the given data; assumes a Jupyter notebook
    environment.

    Parameters
    ----------
    vis_data

    Returns
    -------
    IPython.display.HTML
    &#34;&#34;&#34;
    # CSS styles for displaying pyLDAvis visualisations nicely
    # - Resize to fit visualisations without causing other cells to overflow
    jupyter_styles = &#34;&#34;&#34;
    &lt;style&gt;
        /* These have to be marked important to override pyLDAvis default styles */
        #notebook-container {
            width: 1370px !important;
        }
    
        div.output_area {
            width: unset !important;
        }
        
        div.output_html.rendered_html {
            max-height: unset;
        }
    &lt;/style&gt;
    &#34;&#34;&#34;
    # noinspection PyTypeChecker
    display(HTML(jupyter_styles))

    with warnings.catch_warnings():
        try:
            import IPython.utils.shimmodule

            # Let&#39;s pretend pyLDAvis isn&#39;t a few generations behind ¯\_(ツ)_/¯
            # (Waiting for upstream 2.1.4)
            warnings.simplefilter(
                &#34;ignore&#34;, category=IPython.utils.shimmodule.ShimWarning
            )
        except ModuleNotFoundError:
            pass

        return pyLDAvis.display(vis_data, local=True)


def export_visualisation(vis_data, folder):
    &#34;&#34;&#34;
    Exports a pyLDAvis visualisation of `vis_data` as a HTML file in the given folder

    Attempts to copy the stock visualisation sources (js/css/etc) over rather than
    assuming Internet access is available.

    Parameters
    ----------
    vis_data: pyLDAvis.PreparedData
    folder
    &#34;&#34;&#34;
    folder = pathlib.Path(folder)
    folder.mkdir(exist_ok=True)

    # Copy the pyLDAvis sources
    sources_folder = folder / &#34;src&#34;
    sources_folder.mkdir(exist_ok=True)

    d3_src = pathlib.Path(pyLDAvis.urls.D3_LOCAL)
    ldavis_src = pathlib.Path(pyLDAvis.urls.LDAVIS_LOCAL)
    ldavis_css = pathlib.Path(pyLDAvis.urls.LDAVIS_CSS_LOCAL)
    for src in [d3_src, ldavis_src, ldavis_css]:
        shutil.copy2(src, sources_folder)

    # These urls are relative to the HTML file
    local_urls = {
        &#34;d3_url&#34;: &#34;src/&#34; + d3_src.name,
        &#34;ldavis_url&#34;: &#34;src/&#34; + ldavis_src.name,
        &#34;ldavis_css_url&#34;: &#34;src/&#34; + ldavis_css.name,
    }

    # pyLDAvis expects strings or file objects
    output = str(folder / &#34;visualisation.html&#34;)

    pyLDAvis.save_html(vis_data, output, **local_urls)


def prepare_data(
    model,
    mds=&#34;pcoa&#34;,
    lambda_step=0.1,
    sort_topics=False,
    verbose=False,
    use_optimised=True,
    **other_options,
):
    &#34;&#34;&#34;
    Provides a simple interface for preparing the data for visualisation with pyLDAvis

    Parameters
    ----------
    model: tp.LDAModel
        A trained Tomotopy model
    verbose: bool, optional
        Whether or not to print verbose progress messages
    use_optimised: bool, optional
        Whether to use our optimised, monkey-patched version of the pyLDAvis prepare
        function; will use the original one otherwise.

    mds
    lambda_step
    sort_topics
        These other keyword arguments are pyLDAvis-specific options
        (See pyLDAvis docs for details)
    &#34;&#34;&#34;
    origin_time = time.perf_counter()

    # Convert tomotopy model data to pyLDAvis format
    # ----------------------------------------------

    model_data = {
        &#34;topic_term_dists&#34;: [model.get_topic_word_dist(k) for k in range(model.k)],
        &#34;doc_topic_dists&#34;: [
            model.docs[n].get_topic_dist() for n in range(len(model.docs))
        ],
        &#34;doc_lengths&#34;: [len(model.docs[n].words) for n in range(len(model.docs))],
        &#34;vocab&#34;: model.vocabs,
        &#34;term_frequency&#34;: model.vocab_freq,
    }

    # Since we are doing the actual calculations in a separate thread, we collect the
    # options here to pass them through more neatly
    # (Is there a better way to handle this?)
    options = dict(
        {&#34;mds&#34;: mds, &#34;lambda_step&#34;: lambda_step, &#34;sort_topics&#34;: sort_topics},
        **other_options,
    )

    if verbose:
        print(&#34;Preparing LDA visualisation...&#34;, flush=True, end=&#34;&#34;)

    results = [None]

    if use_optimised:
        # We probably don&#39;t need to start up a separate thread if we are using our
        # monkey-patched optimised prepare function
        _prepare_vis(model_data, options, use_optimised, results)
    else:
        t = threading.Thread(
            target=_prepare_vis, args=(model_data, options, use_optimised, results)
        )
        t.start()

        progress_countdown = 1.0

        while t.is_alive():
            time.sleep(0.1)
            progress_countdown -= 0.1
            if progress_countdown &lt;= 0:
                if verbose:
                    print(&#34; .&#34;, flush=True, end=&#34;&#34;)
                progress_countdown = 1

    vis_data = results[0]
    elapsed = time.perf_counter() - origin_time

    if verbose:
        print(f&#34; Done. ({elapsed:.3f}s)&#34;)

    return vis_data


def _prepare_vis(model_data, options, use_optimised, results):
    &#34;&#34;&#34;
    Helper function to call the `pyLDAvis.prepare` method in a separate thread so
    that we can monitor progress.

    Parameters
    ----------
    model_data
        Raw model data in the format expected by pyLDAvis.
    options: dict
        PyLDAvis options
    use_optimised: bool
        Whether to use our optimised, monkey-patched version of the pyLDAvis prepare
        function; will use the original one otherwise.
    results: iterable
        Single element list to be passed in by reference -- The prepared data will be
        stored here.
    &#34;&#34;&#34;
    if use_optimised:
        vis_data = _fast_prepare(**model_data, **options)
    else:
        vis_data = pyLDAvis.prepare(**model_data, **options)
    results[0] = vis_data


def _fast_prepare(
    topic_term_dists,
    doc_topic_dists,
    doc_lengths,
    vocab,
    term_frequency,
    R=30,
    lambda_step=0.01,
    mds=pyLDAvis.js_PCoA,
    n_jobs=-1,
    plot_opts=None,
    sort_topics=True,
    skip_validate=False,
):
    &#34;&#34;&#34;
    Helper function that runs optimised versions of the pyLDAvis functions to reduce
    runtime complexity, especially for later versions of `pandas` (e.g., &gt; 1.0.0).

    Much of the code will be taken directly from `_prepare.py` in the pyLDAvis
    package (v2.1.2), with modifications noted in the comments.

    Parameters
    ----------
    topic_term_dists : array-like, shape (`n_topics`, `n_terms`)
        Matrix of topic-term probabilities. Where `n_terms` is `len(vocab)`.
    doc_topic_dists : array-like, shape (`n_docs`, `n_topics`)
        Matrix of document-topic probabilities.
    doc_lengths : array-like, shape `n_docs`
        The length of each document, i.e. the number of words in each document.
        The order of the numbers should be consistent with the ordering of the
        docs in `doc_topic_dists`.
    vocab : array-like, shape `n_terms`
        List of all the words in the corpus used to train the model.
    term_frequency : array-like, shape `n_terms`
        The count of each particular term over the entire corpus. The ordering
        of these counts should correspond with `vocab` and `topic_term_dists`.
    R : int
        The number of terms to display in the barcharts of the visualization.
        Default is 30. Recommended to be roughly between 10 and 50.
    lambda_step : float, between 0 and 1
        Determines the interstep distance in the grid of lambda values over
        which to iterate when computing relevance.
        Default is 0.01. Recommended to be between 0.01 and 0.1.
    mds : function or a string representation of function
        A function that takes `topic_term_dists` as an input and outputs a
        `n_topics` by `2`  distance matrix. The output approximates the distance
        between topics. See :func:`js_PCoA` for details on the default function.
        A string representation currently accepts `pcoa` (or upper case variant),
        `mmds` (or upper case variant) and `tsne` (or upper case variant),
        if `sklearn` package is installed for the latter two.
    n_jobs : int
        The number of cores to be used to do the computations. The regular
        joblib conventions are followed so `-1`, which is the default, will
        use all cores.
    plot_opts : dict, with keys &#39;xlab&#39; and `ylab`
        Dictionary of plotting options, right now only used for the axis labels.
    sort_topics : sort topics by topic proportion (percentage of tokens covered). Set
        to false to keep original topic order.

    skip_validate: bool, optional
        If set, will ignore validation errors (e.g., those caused by numerical
        instability).  Use with caution.

    Returns
    -------
    pyLDAvis.PreparedData
    &#34;&#34;&#34;
    # ZW: Make default `plot_opts` immutable
    if plot_opts is None:
        plot_opts = {&#34;xlab&#34;: &#34;PC1&#34;, &#34;ylab&#34;: &#34;PC2&#34;}

    # parse mds
    # ZW: if isinstance(mds, basestring):
    if isinstance(mds, str):
        mds = mds.lower()
        if mds == &#34;pcoa&#34;:
            mds = _prepare.js_PCoA
        elif mds in (&#34;mmds&#34;, &#34;tsne&#34;):
            if _prepare.sklearn_present:
                mds_opts = {&#34;mmds&#34;: _prepare.js_MMDS, &#34;tsne&#34;: _prepare.js_TSNE}
                mds = mds_opts[mds]
            else:
                _prepare.logging.warning(&#34;sklearn not present, switch to PCoA&#34;)
                mds = _prepare.js_PCoA
        else:
            _prepare.logging.warning(&#34;Unknown mds `%s`, switch to PCoA&#34; % mds)
            mds = _prepare.js_PCoA

    # ZW: Pandas is column-oriented, but the tomotopy `topic_term_dists` is naturally
    # arranged by row.  We can save a bunch of data prep runtime by pre-building the
    # DataFrame instead of passing an array of rows to the constructor.
    # (There are way more columns, which otherwise have to be re-constructed from the
    # array, than there are rows -- There are as many columns as terms, but only as
    # many rows as topics)
    topic_term_dist_cols = [
        pd.Series(topic_term_dist, dtype=&#34;float64&#34;)
        for topic_term_dist in topic_term_dists
    ]
    topic_term_dists = pd.concat(topic_term_dist_cols, axis=1).T

    topic_term_dists = _df_with_names(topic_term_dists, &#34;topic&#34;, &#34;term&#34;)
    doc_topic_dists = _df_with_names(doc_topic_dists, &#34;doc&#34;, &#34;topic&#34;)
    term_frequency = _series_with_name(term_frequency, &#34;term_frequency&#34;)
    doc_lengths = _series_with_name(doc_lengths, &#34;doc_length&#34;)
    vocab = _series_with_name(vocab, &#34;vocab&#34;)
    if not skip_validate:
        _prepare._input_validate(
            topic_term_dists, doc_topic_dists, doc_lengths, vocab, term_frequency
        )
    R = min(R, len(vocab))

    topic_freq = doc_topic_dists.mul(doc_lengths, axis=&#34;index&#34;).sum()
    # ZW: topic_freq = (doc_topic_dists.T * doc_lengths).T.sum()
    # topic_freq       = np.dot(doc_topic_dists.T, doc_lengths)
    if sort_topics:
        topic_proportion = (topic_freq / topic_freq.sum()).sort_values(ascending=False)
    else:
        topic_proportion = topic_freq / topic_freq.sum()

    topic_order = topic_proportion.index
    # reorder all data based on new ordering of topics
    topic_freq = topic_freq[topic_order]
    topic_term_dists = topic_term_dists.iloc[topic_order]
    doc_topic_dists = doc_topic_dists[topic_order]

    # token counts for each term-topic combination (widths of red bars)
    term_topic_freq = (topic_term_dists.T * topic_freq).T
    # Quick fix for red bar width bug.  We calculate the
    # term frequencies internally, using the topic term distributions and the
    # topic frequencies, rather than using the user-supplied term frequencies.
    # For a detailed discussion, see: https://github.com/cpsievert/LDAvis/pull/41
    term_frequency = np.sum(term_topic_freq, axis=0)

    topic_info = _topic_info(
        topic_term_dists,
        topic_proportion,
        term_frequency,
        term_topic_freq,
        vocab,
        lambda_step,
        R,
        n_jobs,
    )
    token_table = _prepare._token_table(
        topic_info, term_topic_freq, vocab, term_frequency
    )
    topic_coordinates = _prepare._topic_coordinates(
        mds, topic_term_dists, topic_proportion
    )
    client_topic_order = [x + 1 for x in topic_order]

    return _prepare.PreparedData(
        topic_coordinates,
        topic_info,
        token_table,
        R,
        lambda_step,
        plot_opts,
        client_topic_order,
    )


def _df_with_names(data, index_name, columns_name):
    &#34;&#34;&#34; From `pyLDAvis._prepare.py` &#34;&#34;&#34;
    if type(data) == pd.DataFrame:
        # we want our index to be numbered
        df = pd.DataFrame(data.values)
    else:
        # ZW: `from_records()` might be slightly more performant?
        df = pd.DataFrame.from_records(data)
    df.index.name = index_name
    df.columns.name = columns_name
    return df


def _series_with_name(data, name):
    &#34;&#34;&#34; From `pyLDAvis._prepare.py` &#34;&#34;&#34;
    if type(data) == pd.Series:
        data.name = name
        # ensures a numeric index
        return data.reset_index()[name]
    else:
        return pd.Series(data, name=name)


def _topic_info(
    topic_term_dists,
    topic_proportion,
    term_frequency,
    term_topic_freq,
    vocab,
    lambda_step,
    R,
    n_jobs,
):
    &#34;&#34;&#34; From `pyLDAvis._prepare.py`, optimised &#34;&#34;&#34;
    # marginal distribution over terms (width of blue bars)
    term_proportion = term_frequency / term_frequency.sum()

    # compute the distinctiveness and saliency of the terms:
    # this determines the R terms that are displayed when no topic is selected
    tt_sum = topic_term_dists.sum()
    topic_given_term = pd.eval(&#34;topic_term_dists / tt_sum&#34;)
    # ZW: topic_given_term = topic_term_dists / topic_term_dists.sum()
    log_1 = np.log(pd.eval(&#34;(topic_given_term.T / topic_proportion)&#34;))
    kernel = pd.eval(&#34;topic_given_term * log_1.T&#34;)
    # ZW: kernel = topic_given_term * np.log((topic_given_term.T / topic_proportion).T)
    distinctiveness = kernel.sum()
    saliency = term_proportion * distinctiveness

    # Order the terms for the &#34;default&#34; view by decreasing saliency:
    default_term_info = (
        pd.DataFrame(
            {
                &#34;saliency&#34;: saliency,
                &#34;Term&#34;: vocab,
                &#34;Freq&#34;: term_frequency,
                &#34;Total&#34;: term_frequency,
                &#34;Category&#34;: &#34;Default&#34;,
            }
        )
        .sort_values(by=&#34;saliency&#34;, ascending=False)
        .head(R)
        .drop(&#34;saliency&#34;, 1)
    )
    # Rounding Freq and Total to integer values to match LDAvis code:
    default_term_info[&#34;Freq&#34;] = np.floor(default_term_info[&#34;Freq&#34;])
    default_term_info[&#34;Total&#34;] = np.floor(default_term_info[&#34;Total&#34;])
    ranks = np.arange(R, 0, -1)
    default_term_info[&#34;logprob&#34;] = default_term_info[&#34;loglift&#34;] = ranks

    # compute relevance and top terms for each topic
    log_lift = np.log(pd.eval(&#34;topic_term_dists / term_proportion&#34;)).astype(&#34;float64&#34;)
    # ZW: log_lift = np.log(topic_term_dists / term_proportion)
    log_ttd = np.log(topic_term_dists).astype(&#34;float64&#34;)
    lambda_seq = np.arange(0, 1 + lambda_step, lambda_step)

    def topic_top_term_df(tup):
        new_topic_id, (original_topic_id, topic_terms) = tup
        term_ix = topic_terms.unique()
        # ZW: Changed order below to match `default_term_info`
        return pd.DataFrame(
            {
                &#34;Term&#34;: vocab[term_ix],
                &#34;Freq&#34;: term_topic_freq.loc[original_topic_id, term_ix],
                &#34;Total&#34;: term_frequency[term_ix],
                &#34;Category&#34;: &#34;Topic%d&#34; % new_topic_id,
                &#34;logprob&#34;: log_ttd.loc[original_topic_id, term_ix].round(4),
                &#34;loglift&#34;: log_lift.loc[original_topic_id, term_ix].round(4),
            }
        )

    top_terms = pd.concat(
        # ZW: Parallel(n_jobs=n_jobs)(
        Parallel(n_jobs=n_jobs, prefer=&#34;threads&#34;)(
            delayed(_find_relevance_chunks)(log_ttd, log_lift, R, ls)
            for ls in _prepare._job_chunks(lambda_seq, n_jobs)
        )
    )
    topic_dfs = map(topic_top_term_df, enumerate(top_terms.T.iterrows(), 1))
    return pd.concat([default_term_info] + list(topic_dfs))


def _find_relevance(log_ttd, log_lift, R, lambda_):
    &#34;&#34;&#34; From `pyLDAvis._prepare.py`, optimised &#34;&#34;&#34;
    relevance = lambda_ * log_ttd + (1 - lambda_) * log_lift
    return relevance.T.apply(lambda topic: topic.nlargest(R).index)
    # ZW: return relevance.T.apply(lambda s: s.sort_values(
    # ascending=False).index).head(R)


def _find_relevance_chunks(log_ttd, log_lift, R, lambda_seq):
    &#34;&#34;&#34; From `pyLDAvis._prepare.py` &#34;&#34;&#34;
    return pd.concat([_find_relevance(log_ttd, log_lift, R, l) for l in lambda_seq])</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="ignis.vis.pyldavis.export_visualisation"><code class="name flex">
<span>def <span class="ident">export_visualisation</span></span>(<span>vis_data, folder)</span>
</code></dt>
<dd>
<div class="desc"><p>Exports a pyLDAvis visualisation of <code>vis_data</code> as a HTML file in the given folder</p>
<p>Attempts to copy the stock visualisation sources (js/css/etc) over rather than
assuming Internet access is available.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>vis_data</code></strong> :&ensp;<code>pyLDAvis.PreparedData</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>folder</code></strong></dt>
<dd>&nbsp;</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def export_visualisation(vis_data, folder):
    &#34;&#34;&#34;
    Exports a pyLDAvis visualisation of `vis_data` as a HTML file in the given folder

    Attempts to copy the stock visualisation sources (js/css/etc) over rather than
    assuming Internet access is available.

    Parameters
    ----------
    vis_data: pyLDAvis.PreparedData
    folder
    &#34;&#34;&#34;
    folder = pathlib.Path(folder)
    folder.mkdir(exist_ok=True)

    # Copy the pyLDAvis sources
    sources_folder = folder / &#34;src&#34;
    sources_folder.mkdir(exist_ok=True)

    d3_src = pathlib.Path(pyLDAvis.urls.D3_LOCAL)
    ldavis_src = pathlib.Path(pyLDAvis.urls.LDAVIS_LOCAL)
    ldavis_css = pathlib.Path(pyLDAvis.urls.LDAVIS_CSS_LOCAL)
    for src in [d3_src, ldavis_src, ldavis_css]:
        shutil.copy2(src, sources_folder)

    # These urls are relative to the HTML file
    local_urls = {
        &#34;d3_url&#34;: &#34;src/&#34; + d3_src.name,
        &#34;ldavis_url&#34;: &#34;src/&#34; + ldavis_src.name,
        &#34;ldavis_css_url&#34;: &#34;src/&#34; + ldavis_css.name,
    }

    # pyLDAvis expects strings or file objects
    output = str(folder / &#34;visualisation.html&#34;)

    pyLDAvis.save_html(vis_data, output, **local_urls)</code></pre>
</details>
</dd>
<dt id="ignis.vis.pyldavis.prepare_data"><code class="name flex">
<span>def <span class="ident">prepare_data</span></span>(<span>model, mds='pcoa', lambda_step=0.1, sort_topics=False, verbose=False, use_optimised=True, **other_options)</span>
</code></dt>
<dd>
<div class="desc"><p>Provides a simple interface for preparing the data for visualisation with pyLDAvis</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>model</code></strong> :&ensp;<code>tp.LDAModel</code></dt>
<dd>A trained Tomotopy model</dd>
<dt><strong><code>verbose</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>Whether or not to print verbose progress messages</dd>
<dt><strong><code>use_optimised</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>Whether to use our optimised, monkey-patched version of the pyLDAvis prepare
function; will use the original one otherwise.</dd>
<dt><strong><code>mds</code></strong></dt>
<dd>&nbsp;</dd>
<dt><strong><code>lambda_step</code></strong></dt>
<dd>&nbsp;</dd>
<dt><strong><code>sort_topics</code></strong></dt>
<dd>These other keyword arguments are pyLDAvis-specific options
(See pyLDAvis docs for details)</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def prepare_data(
    model,
    mds=&#34;pcoa&#34;,
    lambda_step=0.1,
    sort_topics=False,
    verbose=False,
    use_optimised=True,
    **other_options,
):
    &#34;&#34;&#34;
    Provides a simple interface for preparing the data for visualisation with pyLDAvis

    Parameters
    ----------
    model: tp.LDAModel
        A trained Tomotopy model
    verbose: bool, optional
        Whether or not to print verbose progress messages
    use_optimised: bool, optional
        Whether to use our optimised, monkey-patched version of the pyLDAvis prepare
        function; will use the original one otherwise.

    mds
    lambda_step
    sort_topics
        These other keyword arguments are pyLDAvis-specific options
        (See pyLDAvis docs for details)
    &#34;&#34;&#34;
    origin_time = time.perf_counter()

    # Convert tomotopy model data to pyLDAvis format
    # ----------------------------------------------

    model_data = {
        &#34;topic_term_dists&#34;: [model.get_topic_word_dist(k) for k in range(model.k)],
        &#34;doc_topic_dists&#34;: [
            model.docs[n].get_topic_dist() for n in range(len(model.docs))
        ],
        &#34;doc_lengths&#34;: [len(model.docs[n].words) for n in range(len(model.docs))],
        &#34;vocab&#34;: model.vocabs,
        &#34;term_frequency&#34;: model.vocab_freq,
    }

    # Since we are doing the actual calculations in a separate thread, we collect the
    # options here to pass them through more neatly
    # (Is there a better way to handle this?)
    options = dict(
        {&#34;mds&#34;: mds, &#34;lambda_step&#34;: lambda_step, &#34;sort_topics&#34;: sort_topics},
        **other_options,
    )

    if verbose:
        print(&#34;Preparing LDA visualisation...&#34;, flush=True, end=&#34;&#34;)

    results = [None]

    if use_optimised:
        # We probably don&#39;t need to start up a separate thread if we are using our
        # monkey-patched optimised prepare function
        _prepare_vis(model_data, options, use_optimised, results)
    else:
        t = threading.Thread(
            target=_prepare_vis, args=(model_data, options, use_optimised, results)
        )
        t.start()

        progress_countdown = 1.0

        while t.is_alive():
            time.sleep(0.1)
            progress_countdown -= 0.1
            if progress_countdown &lt;= 0:
                if verbose:
                    print(&#34; .&#34;, flush=True, end=&#34;&#34;)
                progress_countdown = 1

    vis_data = results[0]
    elapsed = time.perf_counter() - origin_time

    if verbose:
        print(f&#34; Done. ({elapsed:.3f}s)&#34;)

    return vis_data</code></pre>
</details>
</dd>
<dt id="ignis.vis.pyldavis.show_visualisation"><code class="name flex">
<span>def <span class="ident">show_visualisation</span></span>(<span>vis_data)</span>
</code></dt>
<dd>
<div class="desc"><p>Display the pyLDAvis visualisation for the given data; assumes a Jupyter notebook
environment.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>vis_data</code></strong></dt>
<dd>&nbsp;</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>IPython.display.HTML</code></dt>
<dd>&nbsp;</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def show_visualisation(vis_data):
    &#34;&#34;&#34;
    Display the pyLDAvis visualisation for the given data; assumes a Jupyter notebook
    environment.

    Parameters
    ----------
    vis_data

    Returns
    -------
    IPython.display.HTML
    &#34;&#34;&#34;
    # CSS styles for displaying pyLDAvis visualisations nicely
    # - Resize to fit visualisations without causing other cells to overflow
    jupyter_styles = &#34;&#34;&#34;
    &lt;style&gt;
        /* These have to be marked important to override pyLDAvis default styles */
        #notebook-container {
            width: 1370px !important;
        }
    
        div.output_area {
            width: unset !important;
        }
        
        div.output_html.rendered_html {
            max-height: unset;
        }
    &lt;/style&gt;
    &#34;&#34;&#34;
    # noinspection PyTypeChecker
    display(HTML(jupyter_styles))

    with warnings.catch_warnings():
        try:
            import IPython.utils.shimmodule

            # Let&#39;s pretend pyLDAvis isn&#39;t a few generations behind ¯\_(ツ)_/¯
            # (Waiting for upstream 2.1.4)
            warnings.simplefilter(
                &#34;ignore&#34;, category=IPython.utils.shimmodule.ShimWarning
            )
        except ModuleNotFoundError:
            pass

        return pyLDAvis.display(vis_data, local=True)</code></pre>
</details>
</dd>
</dl>
</section>
<section>
</section>
</article>
<nav id="sidebar">
<div style="padding: 1em 0.5em">
<a href="/ignis-tm/ignis">
<div style="display: flex; align-items: center">
<img src="/ignis-tm/images/logo.png" alt="Ignis" height="50"/>
<span style="font-size: 2em; font-weight: 700; margin-left: 0.75em">Ignis</span>
</div>
</a>
</div>
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="ignis.vis" href="index.html">ignis.vis</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="ignis.vis.pyldavis.export_visualisation" href="#ignis.vis.pyldavis.export_visualisation">export_visualisation</a></code></li>
<li><code><a title="ignis.vis.pyldavis.prepare_data" href="#ignis.vis.pyldavis.prepare_data">prepare_data</a></code></li>
<li><code><a title="ignis.vis.pyldavis.show_visualisation" href="#ignis.vis.pyldavis.show_visualisation">show_visualisation</a></code></li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.9.2</a>.</p>
</footer>
</body>
</html>